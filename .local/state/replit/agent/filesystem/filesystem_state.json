{"file_contents":{"app.py":{"content":"import streamlit as st\nimport sys\nfrom pathlib import Path\n\n# Add project root to path\nsys.path.insert(0, str(Path(__file__).parent))\n\nfrom auth.authenticator import AuthManager\nfrom database.db_manager import DatabaseManager\n\n# Page configuration\nst.set_page_config(\n    page_title=\"QuantumBCI - Signal Prediction System\",\n    page_icon=\"🧠\",\n    layout=\"wide\",\n    initial_sidebar_state=\"collapsed\"\n)\n\n# Initialize session state\nif 'authenticated' not in st.session_state:\n    st.session_state.authenticated = False\nif 'user' not in st.session_state:\n    st.session_state.user = None\nif 'db_manager' not in st.session_state:\n    st.session_state.db_manager = DatabaseManager()\ndef main():\n    \"\"\"Main application entry point\"\"\"\n    \n    # Initialize database\n    st.session_state.db_manager.initialize_database()\n    \n    # Check authentication\n    if not st.session_state.authenticated:\n        show_login_page()\n    else:\n        show_main_app()\n\ndef show_login_page():\n    \"\"\"Display login/registration page\"\"\"\n    \n    # Hide sidebar on login page\n    st.markdown(\"\"\"\n    <style>\n    [data-testid=\"stSidebar\"] {\n        display: none;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # Display background image\n    import base64\n    from pathlib import Path\n    \n    # Styling for text with better visibility\n    st.markdown(\"\"\"\n    <style>\n    .main-title {\n        color: #FFFFFF !important;\n        text-align: center;\n        text-shadow: 3px 3px 6px rgba(0,0,0,0.9), 0 0 10px rgba(0,0,0,0.8);\n        margin-bottom: 10px;\n        font-size: 3.5em;\n        font-weight: 700;\n        background: linear-gradient(135deg, #00F5FF, #00D4FF, #0099FF);\n        -webkit-background-clip: text;\n        -webkit-text-fill-color: transparent;\n        background-clip: text;\n        filter: drop-shadow(2px 2px 4px rgba(0,0,0,0.9));\n    }\n    .subtitle {\n        color: #00D4FF !important;\n        text-align: center;\n        text-shadow: 2px 2px 4px rgba(0,0,0,0.9);\n        font-size: 1.5em;\n        font-weight: 500;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # Add neural network background if available\n    bg_image_path = Path(\"attached_assets/stock_images/neural_network_artif_c4fdde89.jpg\")\n    if bg_image_path.exists():\n        with open(bg_image_path, \"rb\") as img_file:\n            encoded = base64.b64encode(img_file.read()).decode()\n            st.markdown(f\"\"\"\n            <style>\n            .stApp {{\n                background-image: linear-gradient(rgba(0, 0, 0, 0.7), rgba(0, 0, 0, 0.7)), url(data:image/jpeg;base64,{encoded});\n                background-size: cover;\n                background-position: center;\n                background-attachment: fixed;\n            }}\n            </style>\n            \"\"\", unsafe_allow_html=True)\n    else:\n        # Fallback to gradient\n        st.markdown(\"\"\"\n        <style>\n        .stApp {\n            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);\n        }\n        </style>\n        \"\"\", unsafe_allow_html=True)\n    \n    st.markdown('<h1 class=\"main-title\">🧠 QuantumBCI Signal Prediction System</h1>', unsafe_allow_html=True)\n    st.markdown('<h3 class=\"subtitle\">Quantum Machine Learning for Brain-Computer Interface Analysis</h3>', unsafe_allow_html=True)\n    \n    col1, col2, col3 = st.columns([1, 2, 1])\n    \n    with col2:\n        st.markdown(\"---\")\n        tab1, tab2 = st.tabs([\"Login\", \"Register\"])\n        \n        with tab1:\n            st.subheader(\"Login to Your Account\")\n            username = st.text_input(\"Username\", key=\"login_username\")\n            password = st.text_input(\"Password\", type=\"password\", key=\"login_password\")\n            \n            if st.button(\"Login\", type=\"primary\", use_container_width=True):\n                auth_manager = AuthManager(st.session_state.db_manager)\n                user = auth_manager.authenticate_user(username, password)\n                \n                if user:\n                    st.session_state.authenticated = True\n                    st.session_state.user = user\n                    \n                    st.session_state.db_manager.log_activity(\n                        user['id'], \n                        'login', \n                        f\"User {username} logged in\"\n                    )\n                    st.success(f\"Welcome back, {user['full_name']}!\")\n                    st.rerun()\n                else:\n                    st.error(\"Invalid username or password\")\n        \n        with tab2:\n            st.subheader(\"Create New Account\")\n            reg_username = st.text_input(\"Username\", key=\"reg_username\")\n            reg_password = st.text_input(\"Password\", type=\"password\", key=\"reg_password\")\n            reg_confirm = st.text_input(\"Confirm Password\", type=\"password\", key=\"reg_confirm\")\n            reg_fullname = st.text_input(\"Full Name\", key=\"reg_fullname\")\n            reg_email = st.text_input(\"Email\", key=\"reg_email\")\n            reg_role = st.selectbox(\"Role\", [\"Researcher\", \"Doctor\"], key=\"reg_role\")\n            \n            if st.button(\"Register\", type=\"primary\", use_container_width=True):\n                if reg_password != reg_confirm:\n                    st.error(\"Passwords do not match\")\n                elif len(reg_password) < 6:\n                    st.error(\"Password must be at least 6 characters\")\n                elif not reg_username or not reg_fullname or not reg_email:\n                    st.error(\"All fields are required\")\n                else:\n                    auth_manager = AuthManager(st.session_state.db_manager)\n                    success, message = auth_manager.register_user(\n                        reg_username, reg_password, reg_fullname, \n                        reg_email, reg_role.lower()\n                    )\n                    \n                    if success:\n                        st.success(message)\n                        st.info(\"Please login with your credentials\")\n                    else:\n                        st.error(message)\n\ndef show_main_app():\n    \"\"\"Display main application interface\"\"\"\n    \n    # Sidebar\n    with st.sidebar:\n        st.title(\"🧠 QuantumBCI\")\n        st.markdown(f\"**User:** {st.session_state.user['full_name']}\")\n        st.markdown(f\"**Role:** {st.session_state.user['role'].title()}\")\n        st.markdown(\"---\")\n        \n        # Navigation info\n        st.markdown(\"### Navigation\")\n        st.info(\"Use the sidebar pages to navigate through the application\")\n        \n        st.markdown(\"---\")\n        \n        if st.button(\"Logout\", type=\"primary\", use_container_width=True):\n            st.session_state.db_manager.log_activity(\n                st.session_state.user['id'],\n                'logout',\n                f\"User {st.session_state.user['username']} logged out\"\n            )\n            st.session_state.authenticated = False\n            st.session_state.user = None\n            st.rerun()\n    \n    # Main content\n    st.title(\"Welcome to QuantumBCI Analysis Platform\")\n    \n    st.markdown(\"\"\"\n    ### 🎯 System Overview\n    \n    This advanced Brain-Computer Interface (BCI) signal prediction system leverages **Quantum Machine Learning** \n    to analyze and predict EEG signals with unprecedented accuracy and efficiency.\n    \n    #### Key Features:\n    - **20-Channel EEG Analysis**: Optimized channel selection from 64-channel data\n    - **Quantum ML Models**: QSVM and Variational Quantum Classifiers using PennyLane\n    - **Classical Comparison**: Benchmark against SVM and Random Forest models\n    - **Real-time Processing**: Upload EDF files for instant analysis\n    - **Brain Metrics**: Alpha, Beta, Theta, Delta band analysis\n    - **PDF Reports**: Comprehensive session reports with visualizations\n    - **Secure Storage**: Encrypted data handling and role-based access\n    \n    #### Quick Start:\n    1. Navigate to **Upload & Analysis** to process EEG data\n    2. View results in **Results** page\n    3. Download PDF reports for documentation\n    4. Manage users and view logs (Admin only)\n    \"\"\")\n    \n    # Statistics\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        total_sessions = st.session_state.db_manager.get_user_session_count(\n            st.session_state.user['id']\n        )\n        st.metric(\"Total Sessions\", total_sessions)\n    \n    with col2:\n        st.metric(\"Active Channels\", \"20\")\n    \n    with col3:\n        st.metric(\"ML Models\", \"5\")\n    \n    with col4:\n        st.metric(\"Quantum Qubits\", \"4-8\")\n    \n    st.markdown(\"---\")\n    \n    # System information\n    st.markdown(\"### 📊 System Capabilities\")\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.markdown(\"\"\"\n        #### Quantum Models\n        - Quantum Support Vector Machine (QSVM)\n        - Variational Quantum Classifier (VQC)\n        - Quantum Kernel Estimation\n        - Amplitude Encoding\n        \"\"\")\n    \n    with col2:\n        st.markdown(\"\"\"\n        #### Classical Models\n        - Support Vector Machine (SVM)\n        - Random Forest Classifier\n        - Feature Extraction (PCA, FFT)\n        - Statistical Analysis\n        \"\"\")\n    \n    st.markdown(\"---\")\n    \n    # Recent activity\n    st.markdown(\"### 📈 Recent Activity\")\n    recent_logs = st.session_state.db_manager.get_recent_activity(\n        st.session_state.user['id'], limit=5\n    )\n    \n    if recent_logs:\n        for log in recent_logs:\n            st.text(f\"{log['timestamp']} - {log['action']}: {log['details']}\")\n    else:\n        st.info(\"No recent activity\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":9548},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"bcrypt>=5.0.0\",\n    \"cryptography>=46.0.2\",\n    \"fpdf>=1.7.2\",\n    \"matplotlib>=3.10.6\",\n    \"mne>=1.10.1\",\n    \"pennylane>=0.42.3\",\n    \"plotly>=6.3.0\",\n    \"pyedflib>=0.1.42\",\n    \"scikit-learn>=1.7.2\",\n    \"scipy>=1.16.2\",\n    \"streamlit>=1.50.0\",\n    \"tensorflow-quantum>=0.7.3\",\n]\n","size_bytes":433},"replit.md":{"content":"# QuantumBCI - Signal Prediction & Real-Time Monitoring System\n\n## Overview\n\nQuantumBCI is a brain-computer interface (BCI) analysis platform that leverages quantum machine learning to predict and analyze EEG signals. The system processes 64-channel EEG data from EDF files, applies advanced signal processing techniques, and uses both quantum and classical machine learning models for comparison and prediction.\n\nThe application features **real-time continuous EEG streaming** with live visualization of brain states including cognitive load, focus, and anxiety detection using machine learning techniques. Blue line charts update continuously to show 20-channel signal flows with sliding-window inference.\n\nThe application is built as a multi-page Streamlit web application with role-based access control, supporting researchers, doctors, and administrators with different permission levels for data access and analysis capabilities.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## Recent UI/UX Improvements (Oct 2025)\n\n**Latest Updates (Oct 1, 2025):**\n1. **Unified Predict Model Page** (`pages/2_Predict_Model.py`): \n   - Consolidated Upload/Analysis and Live Stream into single page\n   - Left column: Upload controls, brain metrics, ML prediction results, stream controls\n   - Right column: Continuous 20-channel signal visualization with real-time brain states\n   - One-click \"Process & Start Streaming\" workflow\n   - Automatic streaming start after upload/processing\n   - Fixed file lifecycle bug: temp files now persist during streaming\n\n2. **Enhanced Login Security & UX**:\n   - Hidden sidebar navigation before login (CSS: `[data-testid=\"stSidebar\"]`)\n   - Improved login text visibility: white text with heavy shadows (3px 3px 6px) against neural network background\n   - Removed insecure Remember Me feature (was URL-based, security vulnerability)\n   - Sidebar auto-expands after successful authentication\n\n3. **Archived Pages**:\n   - Old Upload/Analysis page → `2_Upload_Analysis.py.old`\n   - Old Live Stream page → `4_Live_Stream.py.old`\n   - Navigation simplified to single Predict Model entry point\n\n**Previous Enhancements:**\n1. **Login Page**: Neural network background image with professional styling and dark overlay\n2. **Simplified Upload Flow**: Removed verbose displays, unified workflow, clear progress indicators\n3. **Fixed Calibration**: Shows exact time remaining (e.g., \"Need 14.7s more\")\n4. **Performance Optimization**: Streamlined processing with visual feedback\n\n## System Architecture\n\n### Frontend Architecture\n\n**Problem**: Need for an accessible, interactive interface for EEG analysis with real-time visualization\n**Solution**: Multi-page Streamlit application with role-based dashboards and real-time streaming\n**Rationale**: Streamlit provides rapid prototyping with built-in state management and Python-native visualization libraries\n\n- **Main Entry Point** (`app.py`): Handles authentication flow with hidden sidebar pre-login, routes to main application\n- **Page Structure**: Dashboard, **Predict Model (unified upload/stream)**, Model Comparison, Results, User Management, Activity Logs\n- **Visualization**: Plotly for interactive charts with continuous updates, blue line charts for real-time signals, gauge displays for brain states\n- **State Management**: Streamlit session state for user authentication, database connections, analysis results, and **streaming buffers**\n- **Real-Time Updates**: Auto-refresh at 5Hz for smooth live visualization of continuous EEG signals\n- **Security**: Sidebar hidden on login page, no persistent session tokens (session-based auth only)\n\n### Authentication & Authorization\n\n**Problem**: Secure multi-user access with role-based permissions\n**Solution**: Custom authentication system with bcrypt password hashing and SQLite-based user management\n**Alternatives Considered**: OAuth/third-party auth (rejected for simpler deployment)\n\n- **Password Security**: bcrypt hashing with salt for secure password storage\n- **Role-Based Access Control**: Three user roles (admin, doctor, researcher) with different data export and management permissions\n- **Session Management**: Login state persisted in Streamlit session state with last login tracking\n\n### Data Processing Pipeline\n\n**Problem**: Process high-dimensional 64-channel EEG data efficiently\n**Solution**: Multi-stage preprocessing pipeline with channel selection and artifact removal\n\n1. **EEG File Loading** (`preprocessing/eeg_processor.py`): PyEDFlib for EDF file parsing\n2. **Signal Preprocessing**: Bandpass filtering (0.5-50 Hz), notch filtering (50 Hz power line noise), normalization\n3. **Channel Selection** (`preprocessing/channel_selector.py`): Reduces 64 channels to 20 optimal channels based on 10-20 system priority\n4. **Advanced Signal Processing** (`preprocessing/advanced_signal_processing.py`): ICA-based artifact removal, adaptive filtering, z-score normalization\n5. **Feature Extraction** (`analysis/brain_metrics.py`): Power spectral density, frequency band powers (delta, theta, alpha, beta, gamma)\n\n### Machine Learning Architecture\n\n**Problem**: Compare quantum and classical ML performance on EEG classification\n**Solution**: Parallel implementation of quantum (QSVM, VQC) and classical (SVM, Random Forest) models\n**Pros**: Direct performance comparison, quantum advantage demonstration\n**Cons**: Quantum models have longer processing times\n\n#### Quantum Models\n- **QSVM** (`models/quantum_ml.py`): Quantum kernel-based SVM using PennyLane\n  - 4-qubit quantum feature maps with angle and entanglement encoding\n  - Quantum kernel matrix computation for similarity measurement\n- **Enhanced QSVM** (`models/quantum_enhanced.py`): Deeper circuits with configurable entanglement\n  - Hardware-efficient ansatz with 3-layer depth\n  - Configurable entanglement patterns (circular, linear, full)\n  - 4-8 qubit support\n\n#### Classical Models\n- **SVM** (`models/classical_ml.py`): Scikit-learn RBF kernel SVM\n- **Random Forest**: Ensemble classifier for baseline comparison\n- **Feature Reduction**: PCA for dimensionality reduction (95% variance threshold)\n\n#### Model Configuration\n- Centralized quantum configuration (`config/quantum_config.py`) for hyperparameters\n- Adaptive PCA components based on data size\n- Standardized preprocessing pipeline across all models\n\n### Data Storage\n\n**Problem**: Persist user data, analysis sessions, predictions, and activity logs\n**Solution**: SQLite relational database with structured schema\n**Rationale**: Lightweight, file-based, no separate server required\n\n#### Database Schema (`database/db_manager.py`)\n- **users**: User accounts with roles and authentication\n- **sessions**: EEG analysis sessions with file metadata\n- **predictions**: Model prediction results with accuracy metrics\n- **brain_metrics**: Extracted frequency band powers and metrics\n- **activity_logs**: Audit trail of user actions\n\n#### Data Models (`database/models.py`)\n- Dataclass-based models for type safety: User, Session, Prediction, BrainMetrics\n- SQLite Row factory for dictionary-like access\n\n### Security & Data Protection\n\n**Problem**: Protect sensitive medical EEG data\n**Solution**: Multi-layer security approach (`utils/security.py`)\n\n- **Encryption**: Fernet symmetric encryption for data at rest\n- **Password Hashing**: bcrypt with salt for authentication\n- **Data Integrity**: SHA-256 hashing for verification\n- **Access Control**: Role-based permissions for data export (`utils/data_export.py`)\n\n### Batch Processing\n\n**Problem**: Process multiple EEG files efficiently\n**Solution**: Concurrent batch processor with thread-safe file I/O (`processing/batch_processor.py`)\n\n- ThreadPoolExecutor for parallel file processing\n- Thread-safe EDF reading with locks\n- Configurable worker pool (default 4 workers)\n- Individual error handling per file\n\n### Reporting & Export\n\n**Problem**: Generate shareable analysis reports\n**Solution**: Multi-format export system with role-based filtering\n\n- **PDF Reports** (`reports/pdf_generator.py`): FPDF-based comprehensive reports with session info, metrics, and predictions\n- **Data Export** (`utils/data_export.py`): CSV/JSON export with permission checking\n  - Researchers: metrics, predictions\n  - Doctors: processed data, predictions, metrics\n  - Admins: full access including raw data\n\n### Real-Time Streaming Architecture (NEW)\n\n**Problem**: Enable continuous EEG monitoring with live brain state analysis\n**Solution**: Thread-safe ring buffer + sliding-window inference + EDF replay streaming\n**Rationale**: Real-time insights require continuous data flow, low-latency processing, and smooth visualization\n\n#### Streaming Components\n- **Ring Buffer** (`streaming/ring_buffer.py`): Thread-safe circular buffer for 20 channels, 60-second capacity at 256Hz, supports window extraction and sample appending\n- **EDF Replay Streamer** (`streaming/edf_replay.py`): Simulates live streaming from EDF files at configurable playback speeds (1x-10x), supports looping and callbacks\n- **Brain State ML** (`streaming/brain_state_ml.py`): Real-time detection of cognitive load (theta/beta ratio), focus (engagement index, beta dominance), and anxiety (beta/alpha/theta patterns)\n- **Inference Engine** (`streaming/inference_engine.py`): Sliding-window analysis (2s window, 0.5s hop), EWMA smoothing (alpha=0.3), background thread at ~2Hz, 10-minute history buffer\n- **Predict Model UI** (`pages/2_Predict_Model.py`): Unified page with upload, analysis, and streaming\n  - Left panel: File upload, brain metrics display, ML predictions, stream controls\n  - Right panel: 20-channel blue line visualization (5s window), real-time gauges for cognitive load/focus/anxiety\n  - Automatic workflow: Upload → Process → Stream with single button click\n\n#### Data Flow\n1. EDF Replay → Sample callback (256Hz)\n2. Ring Buffer → Thread-safe storage (60s capacity)\n3. Inference Engine → Sliding window analysis (every 0.5s)\n4. Brain State ML → Cognitive metrics (0-100 scores)\n5. UI Auto-refresh → Plotly updates (5Hz)\n\n#### Brain State Detection\n- **Cognitive Load**: Based on theta/beta ratio (higher theta = more load), calibrated baseline\n- **Focus & Attention**: Engagement index (beta/(alpha+theta)), beta dominance, normalized to baseline\n- **Anxiety**: High beta + low alpha + high theta patterns, multi-factor scoring\n- **Calibration**: 30-second rest period for personalized baseline, per-user z-scoring\n\n## External Dependencies\n\n### Core ML & Quantum Computing\n- **PennyLane**: Quantum machine learning framework for quantum circuits and kernels\n- **NumPy**: Numerical computing and array operations\n- **Scikit-learn**: Classical ML models (SVM, Random Forest), preprocessing, metrics\n\n### Signal Processing\n- **SciPy**: Signal filtering, spectral analysis, statistical functions\n- **MNE**: EEG/MEG data processing (if used beyond PyEDFlib)\n- **PyEDFlib**: EDF file format reading\n\n### Web Framework & Visualization\n- **Streamlit**: Web application framework and UI components\n- **Plotly**: Interactive visualizations and charts\n- **Matplotlib**: Static plotting (supplementary)\n\n### Data Management\n- **SQLite3**: Embedded relational database (Python standard library)\n- **Pandas**: Data manipulation and CSV export\n- **FPDF**: PDF report generation\n\n### Security & Authentication\n- **bcrypt**: Password hashing and verification\n- **cryptography (Fernet)**: Symmetric encryption for data protection\n\n### File Processing\n- **pathlib**: Path manipulation (Python standard library)\n- **tempfile**: Temporary file handling for uploads\n- **pickle**: Python object serialization for encrypted data\n\n### Development & Configuration\n- No external configuration management system - uses Python class-based config (`config/quantum_config.py`)\n- No external database - SQLite file-based storage\n- No external API integrations - self-contained system","size_bytes":11899},"analysis/brain_metrics.py":{"content":"import numpy as np\nfrom scipy import signal\nfrom scipy.integrate import simpson\nfrom typing import Dict, Tuple\n\nclass BrainMetricsAnalyzer:\n    \"\"\"Analyze brain metrics from EEG signals\"\"\"\n    \n    def __init__(self, sampling_rate: float = 256):\n        self.sampling_rate = sampling_rate\n        \n        # Frequency bands (Hz)\n        self.bands = {\n            'delta': (0.5, 4),\n            'theta': (4, 8),\n            'alpha': (8, 13),\n            'beta': (13, 30),\n            'gamma': (30, 50)\n        }\n    \n    def compute_psd(self, data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Compute Power Spectral Density\"\"\"\n        freqs, psd = signal.welch(data, fs=self.sampling_rate, nperseg=int(self.sampling_rate)*2)\n        return freqs, psd\n    \n    def compute_band_power(self, data: np.ndarray, band: Tuple[float, float]) -> float:\n        \"\"\"Compute power in a specific frequency band\"\"\"\n        freqs, psd = self.compute_psd(data)\n        \n        # Find indices of frequencies in band\n        idx_band = np.logical_and(freqs >= band[0], freqs <= band[1])\n        \n        # Compute power using Simpson's rule\n        band_power = simpson(psd[idx_band], x=freqs[idx_band])\n        \n        return band_power\n    \n    def compute_all_band_powers(self, data: np.ndarray) -> Dict[str, float]:\n        \"\"\"Compute power in all frequency bands\"\"\"\n        band_powers = {}\n        \n        for band_name, band_range in self.bands.items():\n            band_powers[band_name] = self.compute_band_power(data, band_range)\n        \n        return band_powers\n    \n    def compute_relative_band_powers(self, data: np.ndarray) -> Dict[str, float]:\n        \"\"\"Compute relative power in all frequency bands\"\"\"\n        band_powers = self.compute_all_band_powers(data)\n        total_power = sum(band_powers.values())\n        \n        relative_powers = {}\n        for band_name, power in band_powers.items():\n            relative_powers[f'{band_name}_relative'] = (power / total_power) * 100 if total_power > 0 else 0\n        \n        return relative_powers\n    \n    def compute_channel_metrics(self, channel_data: np.ndarray) -> Dict:\n        \"\"\"Compute comprehensive metrics for a single channel\"\"\"\n        # Band powers\n        band_powers = self.compute_all_band_powers(channel_data)\n        relative_powers = self.compute_relative_band_powers(channel_data)\n        \n        # Statistical features\n        metrics = {\n            'mean': float(np.mean(channel_data)),\n            'std': float(np.std(channel_data)),\n            'variance': float(np.var(channel_data)),\n            'min': float(np.min(channel_data)),\n            'max': float(np.max(channel_data)),\n            'range': float(np.ptp(channel_data)),\n            'rms': float(np.sqrt(np.mean(channel_data**2)))\n        }\n        \n        # Add band powers\n        metrics.update(band_powers)\n        metrics.update(relative_powers)\n        \n        return metrics\n    \n    def compute_multi_channel_metrics(self, data: np.ndarray) -> Dict:\n        \"\"\"Compute metrics for all channels\"\"\"\n        n_channels = data.shape[0]\n        \n        # Average across all channels\n        avg_data = np.mean(data, axis=0)\n        avg_metrics = self.compute_channel_metrics(avg_data)\n        \n        # Per-channel metrics\n        channel_metrics = []\n        for i in range(n_channels):\n            channel_metrics.append(self.compute_channel_metrics(data[i]))\n        \n        # Aggregate metrics\n        all_metrics = {\n            'average': avg_metrics,\n            'channels': channel_metrics,\n            'n_channels': n_channels\n        }\n        \n        return all_metrics\n    \n    def compute_brain_state(self, data: np.ndarray) -> str:\n        \"\"\"Determine brain state based on dominant frequency band\"\"\"\n        band_powers = self.compute_all_band_powers(np.mean(data, axis=0))\n        \n        # Find dominant band\n        dominant_band = max(band_powers.items(), key=lambda x: x[1])[0]\n        \n        # Map to brain state\n        state_mapping = {\n            'delta': 'Deep Sleep',\n            'theta': 'Drowsy/Meditative',\n            'alpha': 'Relaxed/Wakeful',\n            'beta': 'Active/Alert',\n            'gamma': 'Highly Focused'\n        }\n        \n        return state_mapping.get(dominant_band, 'Unknown')\n    \n    def compute_asymmetry_index(self, left_channel: np.ndarray, \n                               right_channel: np.ndarray, band: str = 'alpha') -> float:\n        \"\"\"Compute hemispheric asymmetry index\"\"\"\n        band_range = self.bands[band]\n        \n        left_power = self.compute_band_power(left_channel, band_range)\n        right_power = self.compute_band_power(right_channel, band_range)\n        \n        # Asymmetry index\n        if left_power + right_power > 0:\n            asymmetry = (right_power - left_power) / (right_power + left_power)\n        else:\n            asymmetry = 0\n        \n        return asymmetry\n    \n    def get_comprehensive_report(self, data: np.ndarray, channel_names: list | None = None) -> Dict:\n        \"\"\"Generate comprehensive brain metrics report\"\"\"\n        avg_data = np.mean(data, axis=0)\n        \n        # Basic metrics\n        band_powers = self.compute_all_band_powers(avg_data)\n        relative_powers = self.compute_relative_band_powers(avg_data)\n        \n        # Brain state\n        brain_state = self.compute_brain_state(data)\n        \n        # Total power\n        total_power = sum(band_powers.values())\n        \n        report = {\n            'brain_state': brain_state,\n            'total_power': total_power,\n            'alpha_power': band_powers['alpha'],\n            'beta_power': band_powers['beta'],\n            'theta_power': band_powers['theta'],\n            'delta_power': band_powers['delta'],\n            'gamma_power': band_powers['gamma'],\n            'alpha_relative': relative_powers['alpha_relative'],\n            'beta_relative': relative_powers['beta_relative'],\n            'theta_relative': relative_powers['theta_relative'],\n            'delta_relative': relative_powers['delta_relative'],\n            'gamma_relative': relative_powers['gamma_relative'],\n            'n_channels': data.shape[0]\n        }\n        \n        if channel_names:\n            report['channel_names'] = channel_names\n        \n        return report\n","size_bytes":6301},"auth/authenticator.py":{"content":"import bcrypt\nfrom typing import Optional, Dict, Tuple\nfrom database.db_manager import DatabaseManager\n\nclass AuthManager:\n    \"\"\"Handles user authentication and authorization\"\"\"\n    \n    def __init__(self, db_manager: DatabaseManager):\n        self.db_manager = db_manager\n    \n    def hash_password(self, password: str) -> str:\n        \"\"\"Hash a password using bcrypt\"\"\"\n        salt = bcrypt.gensalt()\n        hashed = bcrypt.hashpw(password.encode('utf-8'), salt)\n        return hashed.decode('utf-8')\n    \n    def verify_password(self, password: str, password_hash: str) -> bool:\n        \"\"\"Verify a password against its hash\"\"\"\n        return bcrypt.checkpw(password.encode('utf-8'), password_hash.encode('utf-8'))\n    \n    def register_user(self, username: str, password: str, full_name: str,\n                     email: str, role: str = 'researcher') -> Tuple[bool, str]:\n        \"\"\"Register a new user\"\"\"\n        \n        # Validate role\n        valid_roles = ['admin', 'doctor', 'researcher']\n        if role.lower() not in valid_roles:\n            return False, \"Invalid role\"\n        \n        # Hash password\n        password_hash = self.hash_password(password)\n        \n        # Create user\n        user_id = self.db_manager.create_user(\n            username, password_hash, full_name, email, role.lower()\n        )\n        \n        if user_id:\n            return True, \"User registered successfully\"\n        else:\n            return False, \"Username or email already exists\"\n    \n    def authenticate_user(self, username: str, password: str) -> Optional[Dict]:\n        \"\"\"Authenticate a user\"\"\"\n        user = self.db_manager.get_user_by_username(username)\n        \n        if user and self.verify_password(password, user['password_hash']):\n            # Update last login\n            self.db_manager.update_last_login(user['id'])\n            \n            # Remove password hash from returned user\n            user_data = {k: v for k, v in user.items() if k != 'password_hash'}\n            return user_data\n        \n        return None\n    \n    def check_role(self, user: Dict, required_role: str) -> bool:\n        \"\"\"Check if user has required role\"\"\"\n        role_hierarchy = {\n            'admin': 3,\n            'doctor': 2,\n            'researcher': 1\n        }\n        \n        user_level = role_hierarchy.get(user['role'], 0)\n        required_level = role_hierarchy.get(required_role, 0)\n        \n        return user_level >= required_level\n    \n    def is_admin(self, user: Dict) -> bool:\n        \"\"\"Check if user is admin\"\"\"\n        return user['role'] == 'admin'\n","size_bytes":2588},"config/quantum_config.py":{"content":"\"\"\"Quantum Machine Learning Configuration\"\"\"\n\nclass QuantumConfig:\n    \"\"\"Configuration for Quantum ML models\"\"\"\n    \n    # QSVM Configuration\n    QSVM_N_QUBITS = 4\n    QSVM_C_PARAMETER = 1.0\n    \n    # VQC Configuration  \n    VQC_N_QUBITS = 4\n    VQC_N_LAYERS = 3  # Increased depth for better expressiveness\n    VQC_EPOCHS = 50\n    VQC_LEARNING_RATE = 0.1\n    \n    # Feature Processing\n    PCA_VARIANCE_THRESHOLD = 0.95  # Keep 95% of variance\n    \n    # Circuit Architecture\n    ENTANGLEMENT_TYPE = 'circular'  # 'linear' or 'circular'\n    USE_HARDWARE_EFFICIENT = True\n    \n    @classmethod\n    def get_qsvm_config(cls):\n        \"\"\"Get QSVM configuration\"\"\"\n        return {\n            'n_qubits': cls.QSVM_N_QUBITS,\n            'C': cls.QSVM_C_PARAMETER\n        }\n    \n    @classmethod\n    def get_vqc_config(cls):\n        \"\"\"Get VQC configuration\"\"\"\n        return {\n            'n_qubits': cls.VQC_N_QUBITS,\n            'n_layers': cls.VQC_N_LAYERS,\n            'epochs': cls.VQC_EPOCHS,\n            'learning_rate': cls.VQC_LEARNING_RATE\n        }\n","size_bytes":1057},"database/db_manager.py":{"content":"import sqlite3\nimport os\nfrom datetime import datetime\nfrom typing import Optional, Dict, List, Any\nimport json\n\nclass DatabaseManager:\n    \"\"\"Manages database operations for the BCI application\"\"\"\n    \n    def __init__(self, db_path: str = \"quantumbci.db\"):\n        self.db_path = db_path\n    \n    def get_connection(self):\n        \"\"\"Get database connection\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        return conn\n    \n    def initialize_database(self):\n        \"\"\"Initialize database tables\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        # Users table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS users (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                username TEXT UNIQUE NOT NULL,\n                password_hash TEXT NOT NULL,\n                full_name TEXT NOT NULL,\n                email TEXT UNIQUE NOT NULL,\n                role TEXT NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                last_login TIMESTAMP\n            )\n        ''')\n        \n        # Sessions table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS sessions (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                user_id INTEGER NOT NULL,\n                filename TEXT NOT NULL,\n                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                channels_original INTEGER,\n                channels_selected INTEGER,\n                processing_status TEXT,\n                FOREIGN KEY (user_id) REFERENCES users(id)\n            )\n        ''')\n        \n        # Predictions table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS predictions (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                session_id INTEGER NOT NULL,\n                model_type TEXT NOT NULL,\n                model_name TEXT NOT NULL,\n                accuracy REAL,\n                prediction_result TEXT,\n                processing_time REAL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (session_id) REFERENCES sessions(id)\n            )\n        ''')\n        \n        # Brain metrics table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS brain_metrics (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                session_id INTEGER NOT NULL,\n                alpha_power REAL,\n                beta_power REAL,\n                theta_power REAL,\n                delta_power REAL,\n                total_power REAL,\n                metrics_json TEXT,\n                FOREIGN KEY (session_id) REFERENCES sessions(id)\n            )\n        ''')\n        \n        # Activity logs table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS activity_logs (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                user_id INTEGER NOT NULL,\n                action TEXT NOT NULL,\n                details TEXT,\n                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES users(id)\n            )\n        ''')\n        \n        # EEG data table (encrypted storage)\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS eeg_data (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                session_id INTEGER NOT NULL,\n                data_encrypted BLOB,\n                data_hash TEXT,\n                FOREIGN KEY (session_id) REFERENCES sessions(id)\n            )\n        ''')\n        \n        conn.commit()\n        conn.close()\n    \n    def create_user(self, username: str, password_hash: str, full_name: str, \n                   email: str, role: str) -> Optional[int]:\n        \"\"\"Create a new user\"\"\"\n        try:\n            conn = self.get_connection()\n            cursor = conn.cursor()\n            cursor.execute('''\n                INSERT INTO users (username, password_hash, full_name, email, role)\n                VALUES (?, ?, ?, ?, ?)\n            ''', (username, password_hash, full_name, email, role))\n            conn.commit()\n            user_id = cursor.lastrowid\n            conn.close()\n            return user_id\n        except sqlite3.IntegrityError:\n            return None\n    \n    def get_user_by_username(self, username: str) -> Optional[Dict]:\n        \"\"\"Get user by username\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT * FROM users WHERE username = ?', (username,))\n        row = cursor.fetchone()\n        conn.close()\n        \n        if row:\n            return dict(row)\n        return None\n    \n    def update_last_login(self, user_id: int):\n        \"\"\"Update user's last login time\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = ?\n        ''', (user_id,))\n        conn.commit()\n        conn.close()\n    \n    def create_session(self, user_id: int, filename: str, channels_original: int, \n                      channels_selected: int) -> int:\n        \"\"\"Create a new analysis session\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            INSERT INTO sessions (user_id, filename, channels_original, \n                                channels_selected, processing_status)\n            VALUES (?, ?, ?, ?, 'processing')\n        ''', (user_id, filename, channels_original, channels_selected))\n        conn.commit()\n        if not cursor.lastrowid:\n            conn.close()\n            raise Exception(\"Failed to create session - no ID returned\")\n        session_id = cursor.lastrowid\n        conn.close()\n        return session_id\n    \n    def update_session_status(self, session_id: int, status: str):\n        \"\"\"Update session processing status\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            UPDATE sessions SET processing_status = ? WHERE id = ?\n        ''', (status, session_id))\n        conn.commit()\n        conn.close()\n    \n    def save_prediction(self, session_id: int, model_type: str, model_name: str,\n                       accuracy: float, prediction_result: str, processing_time: float) -> int:\n        \"\"\"Save prediction results\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            INSERT INTO predictions (session_id, model_type, model_name, accuracy,\n                                   prediction_result, processing_time)\n            VALUES (?, ?, ?, ?, ?, ?)\n        ''', (session_id, model_type, model_name, accuracy, prediction_result, processing_time))\n        conn.commit()\n        if not cursor.lastrowid:\n            conn.close()\n            raise Exception(\"Failed to save prediction - no ID returned\")\n        pred_id = cursor.lastrowid\n        conn.close()\n        return pred_id\n    \n    def save_brain_metrics(self, session_id: int, alpha: float, beta: float,\n                          theta: float, delta: float, total: float, metrics_dict: Dict):\n        \"\"\"Save brain metrics\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            INSERT INTO brain_metrics (session_id, alpha_power, beta_power,\n                                      theta_power, delta_power, total_power, metrics_json)\n            VALUES (?, ?, ?, ?, ?, ?, ?)\n        ''', (session_id, alpha, beta, theta, delta, total, json.dumps(metrics_dict)))\n        conn.commit()\n        conn.close()\n    \n    def save_eeg_data(self, session_id: int, data_encrypted: bytes, data_hash: str):\n        \"\"\"Save encrypted EEG data\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            INSERT INTO eeg_data (session_id, data_encrypted, data_hash)\n            VALUES (?, ?, ?)\n        ''', (session_id, data_encrypted, data_hash))\n        conn.commit()\n        conn.close()\n    \n    def log_activity(self, user_id: int, action: str, details: str):\n        \"\"\"Log user activity\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            INSERT INTO activity_logs (user_id, action, details)\n            VALUES (?, ?, ?)\n        ''', (user_id, action, details))\n        conn.commit()\n        conn.close()\n    \n    def get_user_sessions(self, user_id: int) -> List[Dict]:\n        \"\"\"Get all sessions for a user\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT * FROM sessions WHERE user_id = ? ORDER BY upload_time DESC\n        ''', (user_id,))\n        rows = cursor.fetchall()\n        conn.close()\n        return [dict(row) for row in rows]\n    \n    def get_session_predictions(self, session_id: int) -> List[Dict]:\n        \"\"\"Get predictions for a session\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT * FROM predictions WHERE session_id = ? ORDER BY created_at\n        ''', (session_id,))\n        rows = cursor.fetchall()\n        conn.close()\n        return [dict(row) for row in rows]\n    \n    def get_session_metrics(self, session_id: int) -> Optional[Dict]:\n        \"\"\"Get brain metrics for a session\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT * FROM brain_metrics WHERE session_id = ?\n        ''', (session_id,))\n        row = cursor.fetchone()\n        conn.close()\n        \n        if row:\n            return dict(row)\n        return None\n    \n    def get_recent_activity(self, user_id: int, limit: int = 10) -> List[Dict]:\n        \"\"\"Get recent activity logs for a user\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT * FROM activity_logs WHERE user_id = ? \n            ORDER BY timestamp DESC LIMIT ?\n        ''', (user_id, limit))\n        rows = cursor.fetchall()\n        conn.close()\n        return [dict(row) for row in rows]\n    \n    def get_all_users(self) -> List[Dict]:\n        \"\"\"Get all users (admin only)\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT id, username, full_name, email, role, created_at, last_login FROM users')\n        rows = cursor.fetchall()\n        conn.close()\n        return [dict(row) for row in rows]\n    \n    def get_user_session_count(self, user_id: int) -> int:\n        \"\"\"Get session count for a user\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT COUNT(*) as count FROM sessions WHERE user_id = ?', (user_id,))\n        count = cursor.fetchone()['count']\n        conn.close()\n        return count\n    \n    def get_all_activity_logs(self, limit: int = 50) -> List[Dict]:\n        \"\"\"Get all activity logs (admin only)\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT al.*, u.username, u.full_name \n            FROM activity_logs al\n            JOIN users u ON al.user_id = u.id\n            ORDER BY al.timestamp DESC LIMIT ?\n        ''', (limit,))\n        rows = cursor.fetchall()\n        conn.close()\n        return [dict(row) for row in rows]\n","size_bytes":11335},"database/models.py":{"content":"from dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional, List\n\n@dataclass\nclass User:\n    \"\"\"User model\"\"\"\n    id: int\n    username: str\n    password_hash: str\n    full_name: str\n    email: str\n    role: str\n    created_at: datetime\n    last_login: Optional[datetime] = None\n\n@dataclass\nclass Session:\n    \"\"\"Analysis session model\"\"\"\n    id: int\n    user_id: int\n    filename: str\n    upload_time: datetime\n    channels_original: int\n    channels_selected: int\n    processing_status: str\n\n@dataclass\nclass Prediction:\n    \"\"\"Prediction result model\"\"\"\n    id: int\n    session_id: int\n    model_type: str\n    model_name: str\n    accuracy: float\n    prediction_result: str\n    processing_time: float\n    created_at: datetime\n\n@dataclass\nclass BrainMetrics:\n    \"\"\"Brain metrics model\"\"\"\n    id: int\n    session_id: int\n    alpha_power: float\n    beta_power: float\n    theta_power: float\n    delta_power: float\n    total_power: float\n    metrics_json: str\n\n@dataclass\nclass ActivityLog:\n    \"\"\"Activity log model\"\"\"\n    id: int\n    user_id: int\n    action: str\n    details: str\n    timestamp: datetime\n","size_bytes":1136},"models/classical_ml.py":{"content":"import numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport time\nfrom typing import Tuple, Dict\n\nclass ClassicalMLModels:\n    \"\"\"Classical Machine Learning models for comparison\"\"\"\n    \n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.pca = None  # Will be initialized adaptively\n    \n    def train_svm(self, X_train: np.ndarray, y_train: np.ndarray) -> Tuple[SVC, float, Dict]:\n        \"\"\"Train classical Support Vector Machine\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_scaled = self.scaler.fit_transform(X_train)\n        # Initialize PCA adaptively based on data size\n        n_components = min(10, X_scaled.shape[0], X_scaled.shape[1])\n        self.pca = PCA(n_components=n_components)\n        X_reduced = self.pca.fit_transform(X_scaled)\n        \n        # Train SVM\n        svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n        svm.fit(X_reduced, y_train)\n        \n        # Training accuracy\n        train_predictions = svm.predict(X_reduced)\n        train_accuracy = accuracy_score(y_train, train_predictions)\n        \n        processing_time = time.time() - start_time\n        \n        metrics = {\n            'training_accuracy': train_accuracy,\n            'processing_time': processing_time,\n            'n_support_vectors': len(svm.support_),\n            'kernel': 'rbf'\n        }\n        \n        return svm, train_accuracy, metrics\n    \n    def predict_svm(self, svm: SVC, X_test: np.ndarray, y_test: np.ndarray | None = None) -> Tuple[np.ndarray, float, Dict]:\n        \"\"\"Predict using SVM\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_scaled = self.scaler.transform(X_test)\n        X_reduced = self.pca.transform(X_scaled)\n        \n        # Predict\n        predictions = svm.predict(X_reduced)\n        \n        processing_time = time.time() - start_time\n        \n        metrics = {'processing_time': processing_time}\n        \n        if y_test is not None:\n            metrics['accuracy'] = accuracy_score(y_test, predictions)\n            metrics['precision'] = precision_score(y_test, predictions, average='weighted', zero_division=0)\n            metrics['recall'] = recall_score(y_test, predictions, average='weighted', zero_division=0)\n            metrics['f1_score'] = f1_score(y_test, predictions, average='weighted', zero_division=0)\n        \n        return predictions, processing_time, metrics\n    \n    def train_random_forest(self, X_train: np.ndarray, y_train: np.ndarray, \n                           n_estimators: int = 100) -> Tuple[RandomForestClassifier, float, Dict]:\n        \"\"\"Train Random Forest classifier\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_scaled = self.scaler.fit_transform(X_train)\n        \n        # Train Random Forest\n        rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=10, random_state=42)\n        rf.fit(X_scaled, y_train)\n        \n        # Training accuracy\n        train_predictions = rf.predict(X_scaled)\n        train_accuracy = accuracy_score(y_train, train_predictions)\n        \n        processing_time = time.time() - start_time\n        \n        metrics = {\n            'training_accuracy': train_accuracy,\n            'processing_time': processing_time,\n            'n_estimators': n_estimators,\n            'feature_importances': rf.feature_importances_.tolist()\n        }\n        \n        return rf, train_accuracy, metrics\n    \n    def predict_random_forest(self, rf: RandomForestClassifier, X_test: np.ndarray, \n                             y_test: np.ndarray | None = None) -> Tuple[np.ndarray, float, Dict]:\n        \"\"\"Predict using Random Forest\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_scaled = self.scaler.transform(X_test)\n        \n        # Predict\n        predictions = rf.predict(X_scaled)\n        \n        processing_time = time.time() - start_time\n        \n        metrics = {'processing_time': processing_time}\n        \n        if y_test is not None:\n            metrics['accuracy'] = accuracy_score(y_test, predictions)\n            metrics['precision'] = precision_score(y_test, predictions, average='weighted', zero_division=0)\n            metrics['recall'] = recall_score(y_test, predictions, average='weighted', zero_division=0)\n            metrics['f1_score'] = f1_score(y_test, predictions, average='weighted', zero_division=0)\n        \n        return predictions, processing_time, metrics\n    \n    def extract_features(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"Extract statistical features from EEG signals\"\"\"\n        features = []\n        \n        for signal in X:\n            # Time domain features\n            mean = np.mean(signal)\n            std = np.std(signal)\n            var = np.var(signal)\n            min_val = np.min(signal)\n            max_val = np.max(signal)\n            range_val = max_val - min_val\n            \n            # Frequency domain features (using FFT)\n            fft = np.fft.fft(signal)\n            fft_magnitude = np.abs(fft[:len(fft)//2])\n            \n            # Spectral features\n            spectral_mean = np.mean(fft_magnitude)\n            spectral_std = np.std(fft_magnitude)\n            spectral_max = np.max(fft_magnitude)\n            \n            feature_vector = [\n                mean, std, var, min_val, max_val, range_val,\n                spectral_mean, spectral_std, spectral_max\n            ]\n            \n            features.append(feature_vector)\n        \n        return np.array(features)\n","size_bytes":5732},"models/quantum_enhanced.py":{"content":"\"\"\"Enhanced Quantum ML Models with Configurable Architecture\"\"\"\nimport pennylane as qml\nimport pennylane.numpy as pnp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom typing import Tuple, Dict\nimport time\n\nclass EnhancedQuantumML:\n    \"\"\"Enhanced Quantum ML with deeper circuits and configurable architecture\"\"\"\n    \n    def __init__(self, n_qubits: int = 4, circuit_depth: int = 3, entanglement: str = 'circular'):\n        self.n_qubits = n_qubits\n        self.circuit_depth = circuit_depth\n        self.entanglement = entanglement\n        self.dev = qml.device('default.qubit', wires=n_qubits)\n        self.scaler = StandardScaler()\n        self.pca: PCA = None  # type: ignore\n    \n    def hardware_efficient_ansatz(self, weights, layer_idx: int):\n        \"\"\"Hardware-efficient ansatz with configurable entanglement\"\"\"\n        # Single-qubit rotations\n        for i in range(self.n_qubits):\n            qml.RY(weights[layer_idx, i, 0], wires=i)\n            qml.RZ(weights[layer_idx, i, 1], wires=i)\n        \n        # Entangling gates\n        if self.entanglement == 'circular':\n            # Full circular entanglement\n            for i in range(self.n_qubits - 1):\n                qml.CNOT(wires=[i, i + 1])\n            if self.n_qubits > 2:\n                qml.CNOT(wires=[self.n_qubits - 1, 0])\n        elif self.entanglement == 'linear':\n            # Linear entanglement\n            for i in range(self.n_qubits - 1):\n                qml.CNOT(wires=[i, i + 1])\n        elif self.entanglement == 'full':\n            # All-to-all entanglement\n            for i in range(self.n_qubits):\n                for j in range(i + 1, self.n_qubits):\n                    qml.CNOT(wires=[i, j])\n    \n    def enhanced_feature_map(self, x):\n        \"\"\"Enhanced feature encoding with angle embedding and entanglement\"\"\"\n        # Angle embedding\n        for i in range(self.n_qubits):\n            qml.RY(x[i], wires=i)\n            qml.RZ(x[i] ** 2, wires=i)  # Non-linear encoding\n        \n        # Feature entanglement\n        for i in range(self.n_qubits - 1):\n            qml.CRZ(x[i] * x[i + 1], wires=[i, i + 1])\n    \n    def deep_quantum_kernel(self, x1, x2):\n        \"\"\"Deep quantum kernel with enhanced feature map\"\"\"\n        @qml.qnode(self.dev)\n        def kernel_circuit(x1, x2):\n            self.enhanced_feature_map(x1)\n            qml.adjoint(self.enhanced_feature_map)(x2)\n            return qml.probs(wires=range(self.n_qubits))\n        \n        probs = kernel_circuit(x1, x2)\n        return probs[0]\n    \n    def quantum_kernel_matrix(self, X1, X2):\n        \"\"\"Compute quantum kernel matrix with enhanced kernel\"\"\"\n        n1, n2 = len(X1), len(X2)\n        kernel_matrix = np.zeros((n1, n2))\n        \n        for i in range(n1):\n            for j in range(n2):\n                kernel_matrix[i, j] = self.deep_quantum_kernel(X1[i], X2[j])\n        \n        return kernel_matrix\n    \n    def train_enhanced_qsvm(self, X_train: np.ndarray, y_train: np.ndarray, C: float = 1.0) -> Tuple[SVC, float, Dict]:\n        \"\"\"Train enhanced QSVM with deep quantum kernel\"\"\"\n        start_time = time.time()\n        \n        # Adaptive PCA\n        X_scaled = self.scaler.fit_transform(X_train)\n        n_components = min(self.n_qubits, X_scaled.shape[0], X_scaled.shape[1])\n        self.pca = PCA(n_components=n_components)\n        X_reduced = self.pca.fit_transform(X_scaled)\n        \n        # Compute enhanced quantum kernel\n        K_train = self.quantum_kernel_matrix(X_reduced, X_reduced)\n        \n        # Train SVM\n        qsvm = SVC(kernel='precomputed', C=C)\n        qsvm.fit(K_train, y_train)\n        \n        train_score = qsvm.score(K_train, y_train)\n        processing_time = time.time() - start_time\n        \n        metrics = {\n            'training_accuracy': train_score,\n            'processing_time': processing_time,\n            'n_support_vectors': len(qsvm.support_),\n            'n_qubits': self.n_qubits,\n            'circuit_depth': self.circuit_depth,\n            'entanglement': self.entanglement,\n            'model_type': 'enhanced_qsvm'\n        }\n        \n        return qsvm, train_score, metrics\n    \n    def predict_enhanced_qsvm(self, qsvm: SVC, X_train: np.ndarray, X_test: np.ndarray) -> Tuple[np.ndarray, float]:\n        \"\"\"Predict using enhanced QSVM\"\"\"\n        start_time = time.time()\n        \n        X_train_scaled = self.scaler.transform(X_train)\n        X_train_reduced = self.pca.transform(X_train_scaled)\n        \n        X_test_scaled = self.scaler.transform(X_test)\n        X_test_reduced = self.pca.transform(X_test_scaled)\n        \n        K_test = self.quantum_kernel_matrix(X_test_reduced, X_train_reduced)\n        predictions = qsvm.predict(K_test)\n        \n        processing_time = time.time() - start_time\n        \n        return predictions, processing_time\n    \n    def get_circuit_info(self) -> Dict:\n        \"\"\"Get circuit configuration information\"\"\"\n        return {\n            'n_qubits': self.n_qubits,\n            'circuit_depth': self.circuit_depth,\n            'entanglement_type': self.entanglement,\n            'total_parameters': self.circuit_depth * self.n_qubits * 2,\n            'gate_count_estimate': self.circuit_depth * self.n_qubits * 3  # Approx gates per layer\n        }\n","size_bytes":5338},"models/quantum_ml.py":{"content":"import numpy as np\nimport pennylane as qml\nfrom pennylane import numpy as pnp\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport time\nfrom typing import Tuple, Dict\n\nclass QuantumMLModels:\n    \"\"\"Quantum Machine Learning models for BCI signal prediction\"\"\"\n    \n    def __init__(self, n_qubits: int = 4):\n        self.n_qubits = n_qubits\n        self.dev = qml.device('default.qubit', wires=n_qubits)\n        self.scaler = StandardScaler()\n        self.pca = None  # Will be initialized adaptively\n    \n    def quantum_feature_map(self, x):\n        \"\"\"Quantum feature map for encoding classical data\"\"\"\n        for i in range(self.n_qubits):\n            qml.RY(x[i], wires=i)\n            qml.RZ(x[i], wires=i)\n        \n        # Entanglement\n        for i in range(self.n_qubits - 1):\n            qml.CNOT(wires=[i, i + 1])\n    \n    def quantum_kernel(self, x1, x2):\n        \"\"\"Quantum kernel function\"\"\"\n        @qml.qnode(self.dev)\n        def kernel_circuit(x1, x2):\n            self.quantum_feature_map(x1)\n            qml.adjoint(self.quantum_feature_map)(x2)\n            return qml.probs(wires=range(self.n_qubits))\n        \n        probs = kernel_circuit(x1, x2)\n        return probs[0]\n    \n    def quantum_kernel_matrix(self, X1, X2):\n        \"\"\"Compute quantum kernel matrix\"\"\"\n        n1, n2 = len(X1), len(X2)\n        kernel_matrix = np.zeros((n1, n2))\n        \n        for i in range(n1):\n            for j in range(n2):\n                kernel_matrix[i, j] = self.quantum_kernel(X1[i], X2[j])\n        \n        return kernel_matrix\n    \n    def train_qsvm(self, X_train: np.ndarray, y_train: np.ndarray) -> Tuple[SVC, float, Dict]:\n        \"\"\"Train Quantum Support Vector Machine\"\"\"\n        start_time = time.time()\n        \n        # Preprocess features\n        X_scaled = self.scaler.fit_transform(X_train)\n        # Initialize PCA adaptively\n        n_components = min(self.n_qubits, X_scaled.shape[0], X_scaled.shape[1])\n        self.pca = PCA(n_components=n_components)\n        X_reduced = self.pca.fit_transform(X_scaled)\n        \n        # Compute quantum kernel matrix\n        K_train = self.quantum_kernel_matrix(X_reduced, X_reduced)\n        \n        # Train SVM with precomputed kernel\n        qsvm = SVC(kernel='precomputed', C=1.0)\n        qsvm.fit(K_train, y_train)\n        \n        # Training accuracy\n        train_score = qsvm.score(K_train, y_train)\n        \n        processing_time = time.time() - start_time\n        \n        metrics = {\n            'training_accuracy': train_score,\n            'processing_time': processing_time,\n            'n_support_vectors': len(qsvm.support_),\n            'n_qubits': self.n_qubits\n        }\n        \n        return qsvm, train_score, metrics\n    \n    def predict_qsvm(self, qsvm: SVC, X_train: np.ndarray, X_test: np.ndarray) -> Tuple[np.ndarray, float]:\n        \"\"\"Predict using QSVM\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_train_scaled = self.scaler.transform(X_train)\n        X_train_reduced = self.pca.transform(X_train_scaled)\n        \n        X_test_scaled = self.scaler.transform(X_test)\n        X_test_reduced = self.pca.transform(X_test_scaled)\n        \n        # Compute kernel between test and train\n        K_test = self.quantum_kernel_matrix(X_test_reduced, X_train_reduced)\n        \n        # Predict\n        predictions = qsvm.predict(K_test)\n        \n        processing_time = time.time() - start_time\n        \n        return predictions, processing_time\n    \n    def variational_quantum_classifier(self, n_layers: int = 2):\n        \"\"\"Create a Variational Quantum Classifier circuit\"\"\"\n        \n        @qml.qnode(self.dev)\n        def vqc_circuit(weights, x):\n            # Encoding\n            self.quantum_feature_map(x)\n            \n            # Variational layers\n            for layer in range(n_layers):\n                for i in range(self.n_qubits):\n                    qml.RY(weights[layer, i, 0], wires=i)\n                    qml.RZ(weights[layer, i, 1], wires=i)\n                \n                for i in range(self.n_qubits - 1):\n                    qml.CNOT(wires=[i, i + 1])\n            \n            return qml.expval(qml.PauliZ(0))\n        \n        return vqc_circuit\n    \n    def train_vqc(self, X_train: np.ndarray, y_train: np.ndarray, \n                  n_layers: int = 2, epochs: int = 50) -> Tuple[np.ndarray, float, Dict]:\n        \"\"\"Train Variational Quantum Classifier\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_scaled = self.scaler.fit_transform(X_train)\n        # Initialize PCA adaptively if not already set\n        if self.pca is None:\n            n_components = min(self.n_qubits, X_scaled.shape[0], X_scaled.shape[1])\n            self.pca = PCA(n_components=n_components)\n        X_reduced = self.pca.fit_transform(X_scaled)\n        \n        # Convert labels to -1, 1\n        y_train_quantum = 2 * y_train - 1\n        \n        # Initialize weights\n        weights = pnp.random.randn(n_layers, self.n_qubits, 2, requires_grad=True)\n        \n        # Create circuit\n        circuit = self.variational_quantum_classifier(n_layers)\n        \n        # Optimizer\n        opt = qml.GradientDescentOptimizer(stepsize=0.1)\n        \n        # Cost function\n        def cost(weights, X, y):\n            predictions = [circuit(weights, x) for x in X]\n            return np.mean((predictions - y) ** 2)\n        \n        # Training loop\n        for epoch in range(epochs):\n            weights = opt.step(lambda w: cost(w, X_reduced, y_train_quantum), weights)\n        \n        # Final accuracy\n        predictions = [circuit(weights, x) for x in X_reduced]\n        predictions_binary = [1 if p > 0 else 0 for p in predictions]\n        train_accuracy = np.mean(np.array(predictions_binary) == y_train)\n        \n        processing_time = time.time() - start_time\n        \n        metrics = {\n            'training_accuracy': train_accuracy,\n            'processing_time': processing_time,\n            'n_layers': n_layers,\n            'epochs': epochs,\n            'n_qubits': self.n_qubits\n        }\n        \n        return weights, train_accuracy, metrics\n    \n    def predict_vqc(self, weights: np.ndarray, X_test: np.ndarray, n_layers: int = 2) -> Tuple[np.ndarray, float]:\n        \"\"\"Predict using VQC\"\"\"\n        start_time = time.time()\n        \n        # Preprocess\n        X_scaled = self.scaler.transform(X_test)\n        X_reduced = self.pca.transform(X_scaled)\n        \n        # Create circuit\n        circuit = self.variational_quantum_classifier(n_layers)\n        \n        # Predict\n        predictions = [circuit(weights, x) for x in X_reduced]\n        predictions_binary = np.array([1 if p > 0 else 0 for p in predictions])\n        \n        processing_time = time.time() - start_time\n        \n        return predictions_binary, processing_time\n    \n    def extract_quantum_features(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"Extract quantum features from classical data\"\"\"\n        \n        @qml.qnode(self.dev)\n        def feature_circuit(x):\n            self.quantum_feature_map(x)\n            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n        \n        # Preprocess\n        X_scaled = self.scaler.fit_transform(X)\n        # Initialize PCA adaptively if not already set\n        if self.pca is None:\n            n_components = min(self.n_qubits, X_scaled.shape[0], X_scaled.shape[1])\n            self.pca = PCA(n_components=n_components)\n        X_reduced = self.pca.fit_transform(X_scaled)\n        \n        # Extract features\n        quantum_features = []\n        for x in X_reduced:\n            features = feature_circuit(x)\n            quantum_features.append(features)\n        \n        return np.array(quantum_features)\n","size_bytes":7811},"pages/1_Dashboard.py":{"content":"import streamlit as st\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom database.db_manager import DatabaseManager\nfrom utils.helpers import Helpers\n\n# Check authentication\nif 'authenticated' not in st.session_state or not st.session_state.authenticated:\n    st.warning(\"Please login first\")\n    st.stop()\n\nst.title(\"📊 Dashboard\")\n\nuser = st.session_state.user\ndb_manager = st.session_state.db_manager\n\n# User statistics\ncol1, col2, col3, col4 = st.columns(4)\n\nwith col1:\n    total_sessions = db_manager.get_user_session_count(user['id'])\n    st.metric(\"Total Sessions\", total_sessions)\n\nwith col2:\n    st.metric(\"Active Models\", \"5\")\n\nwith col3:\n    st.metric(\"Channels\", \"20\")\n\nwith col4:\n    st.metric(\"Quantum Qubits\", \"4-8\")\n\nst.markdown(\"---\")\n\n# Recent sessions\nst.subheader(\"📁 Recent Sessions\")\n\nsessions = db_manager.get_user_sessions(user['id'])\n\nif sessions:\n    # Show only last 10 sessions\n    for session in sessions[:10]:\n        with st.expander(f\"{session['filename']} - {Helpers.format_timestamp(session['upload_time'])}\"):\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.write(f\"**Status:** {session['processing_status']}\")\n                st.write(f\"**Original Channels:** {session['channels_original']}\")\n                st.write(f\"**Selected Channels:** {session['channels_selected']}\")\n            \n            with col2:\n                # Get predictions for this session\n                predictions = db_manager.get_session_predictions(session['id'])\n                if predictions:\n                    st.write(f\"**Models Run:** {len(predictions)}\")\n                    best_acc = max([p['accuracy'] for p in predictions if p['accuracy']])\n                    st.write(f\"**Best Accuracy:** {best_acc:.2%}\")\n                \n                # Get metrics\n                metrics = db_manager.get_session_metrics(session['id'])\n                if metrics:\n                    st.write(f\"**Brain State:** {metrics.get('brain_state', 'N/A')}\")\nelse:\n    st.info(\"No sessions found. Upload an EDF file to get started!\")\n\nst.markdown(\"---\")\n\n# Activity summary\nst.subheader(\"📈 Recent Activity\")\n\nrecent_activity = db_manager.get_recent_activity(user['id'], limit=10)\n\nif recent_activity:\n    for activity in recent_activity:\n        st.text(f\"{Helpers.format_timestamp(activity['timestamp'])} - {activity['action']}: {activity['details']}\")\nelse:\n    st.info(\"No recent activity\")\n","size_bytes":2504},"pages/3_Model_Comparison.py":{"content":"\"\"\"Model Comparison Dashboard - Quantum vs Classical ML\"\"\"\nimport streamlit as st\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport numpy as np\n\nst.set_page_config(page_title=\"Model Comparison\", page_icon=\"📊\", layout=\"wide\")\n\n# Check authentication\nif 'authenticated' not in st.session_state or not st.session_state.authenticated:\n    st.warning(\"⚠️ Please login from the main page\")\n    st.stop()\n\nst.title(\"🔬 Quantum vs Classical ML Comparison\")\nst.markdown(\"### Comprehensive Model Performance Analysis\")\n\n# Create tabs for different views\ntab1, tab2, tab3, tab4 = st.tabs([\"📈 Performance Metrics\", \"⚡ Processing Speed\", \"🎯 Accuracy Analysis\", \"🔍 Detailed Comparison\"])\n\n# Sample data structure - will be populated from session state\nif 'model_results' not in st.session_state:\n    st.session_state.model_results = {\n        'quantum_models': [\n            {'name': 'QSVM', 'accuracy': 0.8571, 'precision': 0.85, 'recall': 0.86, 'f1': 0.855, \n             'processing_time': 0.891, 'n_qubits': 4, 'type': 'quantum'},\n            {'name': 'Enhanced QSVM', 'accuracy': 0.9286, 'precision': 0.92, 'recall': 0.93, 'f1': 0.925,\n             'processing_time': 1.031, 'n_qubits': 4, 'type': 'quantum'},\n        ],\n        'classical_models': [\n            {'name': 'SVM', 'accuracy': 0.6667, 'precision': 0.65, 'recall': 0.68, 'f1': 0.665,\n             'processing_time': 0.042, 'type': 'classical'},\n            {'name': 'Random Forest', 'accuracy': 0.6667, 'precision': 0.64, 'recall': 0.69, 'f1': 0.665,\n             'processing_time': 0.018, 'type': 'classical'},\n        ]\n    }\n\nmodel_results = st.session_state.model_results\n\n# Tab 1: Performance Metrics\nwith tab1:\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.subheader(\"🎯 Accuracy Comparison\")\n        \n        # Prepare data\n        all_models = model_results['quantum_models'] + model_results['classical_models']\n        df = pd.DataFrame(all_models)\n        \n        # Create bar chart\n        fig = go.Figure()\n        \n        quantum_df = df[df['type'] == 'quantum']\n        classical_df = df[df['type'] == 'classical']\n        \n        fig.add_trace(go.Bar(\n            x=quantum_df['name'],\n            y=quantum_df['accuracy'] * 100,\n            name='Quantum Models',\n            marker_color='#8B5CF6',\n            text=[f\"{acc:.1f}%\" for acc in quantum_df['accuracy'] * 100],\n            textposition='auto',\n        ))\n        \n        fig.add_trace(go.Bar(\n            x=classical_df['name'],\n            y=classical_df['accuracy'] * 100,\n            name='Classical Models',\n            marker_color='#10B981',\n            text=[f\"{acc:.1f}%\" for acc in classical_df['accuracy'] * 100],\n            textposition='auto',\n        ))\n        \n        fig.update_layout(\n            title=\"Model Accuracy Comparison\",\n            xaxis_title=\"Model\",\n            yaxis_title=\"Accuracy (%)\",\n            height=400,\n            barmode='group'\n        )\n        \n        st.plotly_chart(fig, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"📊 F1-Score Comparison\")\n        \n        # F1 Score comparison\n        fig_f1 = go.Figure()\n        \n        fig_f1.add_trace(go.Bar(\n            x=quantum_df['name'],\n            y=quantum_df['f1'] * 100,\n            name='Quantum Models',\n            marker_color='#8B5CF6',\n            text=[f\"{f1:.1f}%\" for f1 in quantum_df['f1'] * 100],\n            textposition='auto',\n        ))\n        \n        fig_f1.add_trace(go.Bar(\n            x=classical_df['name'],\n            y=classical_df['f1'] * 100,\n            name='Classical Models',\n            marker_color='#10B981',\n            text=[f\"{f1:.1f}%\" for f1 in classical_df['f1'] * 100],\n            textposition='auto',\n        ))\n        \n        fig_f1.update_layout(\n            title=\"Model F1-Score Comparison\",\n            xaxis_title=\"Model\",\n            yaxis_title=\"F1-Score (%)\",\n            height=400,\n            barmode='group'\n        )\n        \n        st.plotly_chart(fig_f1, use_container_width=True)\n    \n    # Precision-Recall comparison\n    st.subheader(\"🎯 Precision vs Recall\")\n    \n    fig_pr = go.Figure()\n    \n    for model in all_models:\n        color = '#8B5CF6' if model['type'] == 'quantum' else '#10B981'\n        fig_pr.add_trace(go.Scatter(\n            x=[model['precision']],\n            y=[model['recall']],\n            mode='markers+text',\n            name=model['name'],\n            marker=dict(size=15, color=color),\n            text=[model['name']],\n            textposition='top center'\n        ))\n    \n    fig_pr.update_layout(\n        title=\"Precision vs Recall Analysis\",\n        xaxis_title=\"Precision\",\n        yaxis_title=\"Recall\",\n        height=400\n    )\n    \n    st.plotly_chart(fig_pr, use_container_width=True)\n\n# Tab 2: Processing Speed\nwith tab2:\n    st.subheader(\"⚡ Processing Time Analysis\")\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # Processing time bar chart\n        fig_time = go.Figure()\n        \n        fig_time.add_trace(go.Bar(\n            x=quantum_df['name'],\n            y=quantum_df['processing_time'],\n            name='Quantum Models',\n            marker_color='#8B5CF6',\n            text=[f\"{t:.3f}s\" for t in quantum_df['processing_time']],\n            textposition='auto',\n        ))\n        \n        fig_time.add_trace(go.Bar(\n            x=classical_df['name'],\n            y=classical_df['processing_time'],\n            name='Classical Models',\n            marker_color='#10B981',\n            text=[f\"{t:.3f}s\" for t in classical_df['processing_time']],\n            textposition='auto',\n        ))\n        \n        fig_time.update_layout(\n            title=\"Processing Time Comparison\",\n            xaxis_title=\"Model\",\n            yaxis_title=\"Time (seconds)\",\n            height=400,\n            barmode='group'\n        )\n        \n        st.plotly_chart(fig_time, use_container_width=True)\n    \n    with col2:\n        # Speed efficiency (accuracy per second)\n        fastest_idx = df['processing_time'].argmin()\n        st.metric(\"⚡ Fastest Model\", \n                  df.iloc[fastest_idx]['name'],\n                  f\"{df.iloc[fastest_idx]['processing_time']:.3f}s\")\n        \n        st.metric(\"🏆 Most Accurate\", \n                  df.iloc[df['accuracy'].argmax()]['name'],\n                  f\"{df['accuracy'].max():.2%}\")\n        \n        # Efficiency metric: accuracy/time\n        df['efficiency'] = df['accuracy'] / df['processing_time']\n        best_efficiency = df.iloc[df['efficiency'].argmax()]\n        st.metric(\"⚖️ Best Efficiency (Acc/Time)\", \n                  best_efficiency['name'],\n                  f\"{best_efficiency['efficiency']:.2f}\")\n\n# Tab 3: Accuracy Analysis\nwith tab3:\n    st.subheader(\"🎯 Detailed Accuracy Analysis\")\n    \n    # Radar chart for model comparison\n    categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n    \n    fig_radar = go.Figure()\n    \n    for model in all_models:\n        fig_radar.add_trace(go.Scatterpolar(\n            r=[model['accuracy']*100, model['precision']*100, \n               model['recall']*100, model['f1']*100],\n            theta=categories,\n            fill='toself',\n            name=model['name']\n        ))\n    \n    fig_radar.update_layout(\n        polar=dict(radialaxis=dict(visible=True, range=[0, 100])),\n        showlegend=True,\n        title=\"Multi-Metric Model Comparison (Radar Chart)\",\n        height=500\n    )\n    \n    st.plotly_chart(fig_radar, use_container_width=True)\n    \n    # Performance table\n    st.subheader(\"📊 Performance Summary Table\")\n    \n    summary_df = pd.DataFrame(all_models)\n    summary_df = summary_df[['name', 'type', 'accuracy', 'precision', 'recall', 'f1', 'processing_time']]\n    summary_df.columns = ['Model', 'Type', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Time (s)']\n    \n    # Format percentages\n    for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n        summary_df[col] = summary_df[col].apply(lambda x: f\"{x:.2%}\")  # type: ignore\n    \n    summary_df['Time (s)'] = summary_df['Time (s)'].apply(lambda x: f\"{x:.3f}\")  # type: ignore\n    \n    st.dataframe(summary_df, use_container_width=True)\n\n# Tab 4: Detailed Comparison\nwith tab4:\n    st.subheader(\"🔍 Quantum Advantage Analysis\")\n    \n    col1, col2, col3 = st.columns(3)\n    \n    # Calculate quantum advantage\n    best_quantum = max([m['accuracy'] for m in model_results['quantum_models']])\n    best_classical = max([m['accuracy'] for m in model_results['classical_models']])\n    quantum_advantage = (best_quantum - best_classical) / (best_classical + 1e-10) * 100\n    \n    with col1:\n        st.metric(\"🚀 Quantum Advantage\", \n                  f\"{quantum_advantage:.1f}%\",\n                  \"Higher accuracy than classical\")\n    \n    with col2:\n        avg_quantum_time = np.mean([m['processing_time'] for m in model_results['quantum_models']])\n        avg_classical_time = np.mean([m['processing_time'] for m in model_results['classical_models']])\n        st.metric(\"⏱️ Avg Quantum Time\", \n                  f\"{avg_quantum_time:.3f}s\",\n                  f\"+{(avg_quantum_time/avg_classical_time - 1)*100:.0f}% vs classical\")\n    \n    with col3:\n        st.metric(\"🎯 Best Overall Model\",\n                  df.iloc[df['accuracy'].argmax()]['name'],\n                  f\"{df['accuracy'].max():.2%} accuracy\")\n    \n    # Quantum model details\n    st.subheader(\"⚛️ Quantum Model Configuration\")\n    \n    quantum_config_data = []\n    for qm in model_results['quantum_models']:\n        quantum_config_data.append({\n            'Model': qm['name'],\n            'Qubits': qm.get('n_qubits', 'N/A'),\n            'Accuracy': f\"{qm['accuracy']:.2%}\",\n            'Time': f\"{qm['processing_time']:.3f}s\",\n            'Type': 'Quantum Kernel SVM'\n        })\n    \n    st.dataframe(pd.DataFrame(quantum_config_data), use_container_width=True)\n    \n    # Recommendations\n    st.subheader(\"💡 Model Selection Recommendations\")\n    \n    st.info(\"\"\"\n    **When to use Quantum Models:**\n    - High-accuracy requirements (medical diagnosis, critical applications)\n    - Complex pattern recognition in high-dimensional data\n    - When computational resources allow for longer processing times\n    \n    **When to use Classical Models:**\n    - Real-time predictions needed (< 50ms response time)\n    - Resource-constrained environments\n    - When accuracy difference is acceptable for the use case\n    \"\"\")\n    \n    # Statistical significance\n    st.subheader(\"📈 Statistical Insights\")\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.write(\"**Quantum Models:**\")\n        st.write(f\"- Average Accuracy: {np.mean([m['accuracy'] for m in model_results['quantum_models']]):.2%}\")\n        st.write(f\"- Std Dev: {np.std([m['accuracy'] for m in model_results['quantum_models']]):.4f}\")\n        st.write(f\"- Average Time: {avg_quantum_time:.3f}s\")\n    \n    with col2:\n        st.write(\"**Classical Models:**\")\n        st.write(f\"- Average Accuracy: {np.mean([m['accuracy'] for m in model_results['classical_models']]):.2%}\")\n        st.write(f\"- Std Dev: {np.std([m['accuracy'] for m in model_results['classical_models']]):.4f}\")\n        st.write(f\"- Average Time: {avg_classical_time:.3f}s\")\n\n# Footer\nst.markdown(\"---\")\nst.caption(f\"👤 Logged in as: {st.session_state.get('username', 'Unknown')} | Role: {st.session_state.get('role', 'Unknown')}\")\n","size_bytes":11478},"pages/3_Results.py":{"content":"import streamlit as st\nimport sys\nfrom pathlib import Path\nimport os\n\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom reports.pdf_generator import PDFReportGenerator\nfrom utils.helpers import Helpers\n\n# Check authentication\nif 'authenticated' not in st.session_state or not st.session_state.authenticated:\n    st.warning(\"Please login first\")\n    st.stop()\n\nst.title(\"📋 Results & Reports\")\n\nuser = st.session_state.user\ndb_manager = st.session_state.db_manager\n\n# Get user sessions\nsessions = db_manager.get_user_sessions(user['id'])\n\nif not sessions:\n    st.info(\"No analysis sessions found. Upload an EDF file to get started!\")\n    st.stop()\n\n# Session selector\nst.subheader(\"Select Session\")\n\nsession_options = {\n    f\"{s['filename']} - {Helpers.format_timestamp(s['upload_time'])}\": s['id'] \n    for s in sessions\n}\n\nselected_session_name = st.selectbox(\"Choose a session\", list(session_options.keys()))\nselected_session_id = session_options[selected_session_name]\n\n# Get session details\nselected_session = next(s for s in sessions if s['id'] == selected_session_id)\n\nst.markdown(\"---\")\n\n# Session information\nst.subheader(\"📊 Session Information\")\n\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    st.metric(\"Status\", selected_session['processing_status'])\n\nwith col2:\n    st.metric(\"Original Channels\", selected_session['channels_original'])\n\nwith col3:\n    st.metric(\"Selected Channels\", selected_session['channels_selected'])\n\n# Brain metrics\nst.markdown(\"---\")\nst.subheader(\"🧠 Brain Metrics\")\n\nmetrics = db_manager.get_session_metrics(selected_session_id)\n\nif metrics:\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        st.metric(\"Alpha Power\", f\"{metrics['alpha_power']:.4f} μV²\")\n    \n    with col2:\n        st.metric(\"Beta Power\", f\"{metrics['beta_power']:.4f} μV²\")\n    \n    with col3:\n        st.metric(\"Theta Power\", f\"{metrics['theta_power']:.4f} μV²\")\n    \n    with col4:\n        st.metric(\"Delta Power\", f\"{metrics['delta_power']:.4f} μV²\")\n    \n    # Band power distribution\n    st.markdown(\"#### Relative Band Powers\")\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # Get metrics JSON\n        import json\n        metrics_dict = json.loads(metrics['metrics_json']) if metrics.get('metrics_json') else {}\n        \n        if metrics_dict:\n            st.write(\"**Alpha:**\", f\"{metrics_dict.get('alpha_relative', 0):.2f}%\")\n            st.write(\"**Beta:**\", f\"{metrics_dict.get('beta_relative', 0):.2f}%\")\n            st.write(\"**Theta:**\", f\"{metrics_dict.get('theta_relative', 0):.2f}%\")\n    \n    with col2:\n        if metrics_dict:\n            st.write(\"**Delta:**\", f\"{metrics_dict.get('delta_relative', 0):.2f}%\")\n            st.write(\"**Gamma:**\", f\"{metrics_dict.get('gamma_relative', 0):.2f}%\")\n            st.write(\"**Brain State:**\", metrics_dict.get('brain_state', 'N/A'))\n\nelse:\n    st.info(\"No brain metrics available for this session\")\n\n# Predictions\nst.markdown(\"---\")\nst.subheader(\"🤖 Model Predictions\")\n\npredictions = db_manager.get_session_predictions(selected_session_id)\n\nif predictions:\n    # Create predictions table\n    pred_data = []\n    for pred in predictions:\n        pred_data.append({\n            'Model': pred['model_name'],\n            'Type': pred['model_type'],\n            'Accuracy': f\"{pred['accuracy']:.2%}\" if pred['accuracy'] else 'N/A',\n            'Processing Time': f\"{pred['processing_time']:.3f}s\" if pred['processing_time'] else 'N/A',\n            'Timestamp': Helpers.format_timestamp(pred['created_at'])\n        })\n    \n    st.table(pred_data)\n    \n    # Best model\n    best_pred = max(predictions, key=lambda x: x['accuracy'] if x['accuracy'] else 0)\n    st.success(f\"🏆 Best Model: {best_pred['model_name']} with {best_pred['accuracy']:.2%} accuracy\")\n    \nelse:\n    st.info(\"No predictions available for this session\")\n\n# PDF Report Generation\nst.markdown(\"---\")\nst.subheader(\"📄 Generate PDF Report\")\n\nif st.button(\"Generate PDF Report\", type=\"primary\"):\n    \n    if not predictions or not metrics:\n        st.warning(\"Both brain metrics and predictions are required for PDF generation\")\n    else:\n        with st.spinner(\"Generating PDF report...\"):\n            try:\n                # Prepare data\n                session_data = {\n                    'filename': selected_session['filename'],\n                    'upload_time': Helpers.format_timestamp(selected_session['upload_time']),\n                    'channels_original': selected_session['channels_original'],\n                    'channels_selected': selected_session['channels_selected'],\n                    'processing_status': selected_session['processing_status']\n                }\n                \n                import json\n                metrics_dict = json.loads(metrics['metrics_json']) if metrics.get('metrics_json') else {}\n                \n                prediction_list = []\n                for pred in predictions:\n                    prediction_list.append({\n                        'model_name': pred['model_name'],\n                        'model_type': pred['model_type'],\n                        'accuracy': pred['accuracy'],\n                        'processing_time': pred['processing_time']\n                    })\n                \n                # Generate PDF\n                pdf_gen = PDFReportGenerator()\n                \n                # Ensure reports directory exists\n                Helpers.ensure_directory('reports_output')\n                \n                output_path = f\"reports_output/report_{selected_session_id}_{user['id']}.pdf\"\n                pdf_path = pdf_gen.create_report(session_data, metrics_dict, prediction_list, output_path)\n                \n                # Log activity\n                db_manager.log_activity(\n                    user['id'],\n                    'report',\n                    f\"Generated PDF report for session {selected_session_id}\"\n                )\n                \n                st.success(\"✓ PDF report generated successfully!\")\n                \n                # Download button\n                with open(pdf_path, 'rb') as f:\n                    st.download_button(\n                        label=\"📥 Download PDF Report\",\n                        data=f,\n                        file_name=f\"QuantumBCI_Report_{selected_session['filename']}.pdf\",\n                        mime=\"application/pdf\"\n                    )\n            \n            except Exception as e:\n                st.error(f\"Error generating PDF: {str(e)}\")\n                db_manager.log_activity(user['id'], 'error', f\"PDF generation failed: {str(e)}\")\n","size_bytes":6602},"pages/4_User_Management.py":{"content":"import streamlit as st\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom auth.authenticator import AuthManager\nfrom utils.helpers import Helpers\n\n# Check authentication\nif 'authenticated' not in st.session_state or not st.session_state.authenticated:\n    st.warning(\"Please login first\")\n    st.stop()\n\nuser = st.session_state.user\ndb_manager = st.session_state.db_manager\n\n# Check if user is admin\nauth_manager = AuthManager(db_manager)\n\nif not auth_manager.is_admin(user):\n    st.error(\"⛔ Access Denied: Admin privileges required\")\n    st.stop()\n\nst.title(\"👥 User Management\")\n\n# Get all users\nusers = db_manager.get_all_users()\n\nst.subheader(\"All Users\")\n\n# Users table\nuser_data = []\nfor u in users:\n    user_data.append({\n        'ID': u['id'],\n        'Username': u['username'],\n        'Full Name': u['full_name'],\n        'Email': u['email'],\n        'Role': u['role'].title(),\n        'Created': Helpers.format_timestamp(u['created_at']),\n        'Last Login': Helpers.format_timestamp(u['last_login']) if u['last_login'] else 'Never'\n    })\n\nst.table(user_data)\n\nst.markdown(\"---\")\n\n# User statistics\nst.subheader(\"📊 User Statistics\")\n\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    total_users = len(users)\n    st.metric(\"Total Users\", total_users)\n\nwith col2:\n    admins = sum(1 for u in users if u['role'] == 'admin')\n    st.metric(\"Admins\", admins)\n\nwith col3:\n    researchers = sum(1 for u in users if u['role'] == 'researcher')\n    st.metric(\"Researchers\", researchers)\n\nst.markdown(\"---\")\n\n# Add new user (admin only)\nst.subheader(\"➕ Add New User\")\n\nwith st.form(\"add_user_form\"):\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        new_username = st.text_input(\"Username\")\n        new_fullname = st.text_input(\"Full Name\")\n        new_email = st.text_input(\"Email\")\n    \n    with col2:\n        new_password = st.text_input(\"Password\", type=\"password\")\n        new_confirm = st.text_input(\"Confirm Password\", type=\"password\")\n        new_role = st.selectbox(\"Role\", [\"Admin\", \"Doctor\", \"Researcher\"])\n    \n    submitted = st.form_submit_button(\"Add User\", type=\"primary\")\n    \n    if submitted:\n        if new_password != new_confirm:\n            st.error(\"Passwords do not match\")\n        elif len(new_password) < 6:\n            st.error(\"Password must be at least 6 characters\")\n        elif not new_username or not new_fullname or not new_email:\n            st.error(\"All fields are required\")\n        else:\n            success, message = auth_manager.register_user(\n                new_username, new_password, new_fullname,\n                new_email, new_role.lower()\n            )\n            \n            if success:\n                st.success(message)\n                db_manager.log_activity(\n                    user['id'],\n                    'user_created',\n                    f\"Created new user: {new_username} ({new_role})\"\n                )\n                st.rerun()\n            else:\n                st.error(message)\n","size_bytes":3017},"pages/5_Activity_Logs.py":{"content":"import streamlit as st\nimport sys\nfrom pathlib import Path\nimport pandas as pd\n\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom auth.authenticator import AuthManager\nfrom utils.helpers import Helpers\n\n# Check authentication\nif 'authenticated' not in st.session_state or not st.session_state.authenticated:\n    st.warning(\"Please login first\")\n    st.stop()\n\nuser = st.session_state.user\ndb_manager = st.session_state.db_manager\nauth_manager = AuthManager(db_manager)\n\nst.title(\"📜 Activity Logs\")\n\n# Check permissions\nis_admin = auth_manager.is_admin(user)\n\nif is_admin:\n    st.subheader(\"All System Activity (Admin View)\")\n    \n    # Get all activity logs\n    limit = st.slider(\"Number of logs to display\", 10, 200, 50)\n    \n    all_logs = db_manager.get_all_activity_logs(limit=limit)\n    \n    if all_logs:\n        # Convert to DataFrame for better display\n        df_data = []\n        for log in all_logs:\n            df_data.append({\n                'Timestamp': Helpers.format_timestamp(log['timestamp']),\n                'User': f\"{log['full_name']} ({log['username']})\",\n                'Action': log['action'],\n                'Details': log['details']\n            })\n        \n        df = pd.DataFrame(df_data)\n        st.dataframe(df, use_container_width=True)\n    else:\n        st.info(\"No activity logs found\")\n\nelse:\n    st.subheader(\"Your Activity\")\n    \n    # Get user's activity logs\n    limit = st.slider(\"Number of logs to display\", 10, 100, 20)\n    \n    user_logs = db_manager.get_recent_activity(user['id'], limit=limit)\n    \n    if user_logs:\n        # Convert to DataFrame\n        df_data = []\n        for log in user_logs:\n            df_data.append({\n                'Timestamp': Helpers.format_timestamp(log['timestamp']),\n                'Action': log['action'],\n                'Details': log['details']\n            })\n        \n        df = pd.DataFrame(df_data)\n        st.dataframe(df, use_container_width=True)\n    else:\n        st.info(\"No activity logs found\")\n\n# Activity statistics\nst.markdown(\"---\")\nst.subheader(\"📊 Activity Summary\")\n\nif is_admin:\n    all_logs = db_manager.get_all_activity_logs(limit=1000)\n    \n    if all_logs:\n        # Action type distribution\n        action_counts = {}\n        for log in all_logs:\n            action = log['action']\n            action_counts[action] = action_counts.get(action, 0) + 1\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            st.metric(\"Total Actions\", len(all_logs))\n        \n        with col2:\n            st.metric(\"Unique Actions\", len(action_counts))\n        \n        with col3:\n            most_common = max(action_counts.items(), key=lambda x: x[1])[0]\n            st.metric(\"Most Common\", most_common)\n        \n        # Action breakdown\n        st.markdown(\"#### Action Breakdown\")\n        \n        action_df = pd.DataFrame([\n            {'Action': k, 'Count': v} \n            for k, v in sorted(action_counts.items(), key=lambda x: x[1], reverse=True)\n        ])\n        \n        st.bar_chart(action_df.set_index('Action'))\n\nelse:\n    user_logs = db_manager.get_recent_activity(user['id'], limit=1000)\n    \n    if user_logs:\n        # Action type distribution\n        action_counts = {}\n        for log in user_logs:\n            action = log['action']\n            action_counts[action] = action_counts.get(action, 0) + 1\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.metric(\"Your Total Actions\", len(user_logs))\n        \n        with col2:\n            st.metric(\"Action Types\", len(action_counts))\n        \n        # Action breakdown\n        st.markdown(\"#### Your Activity Breakdown\")\n        \n        for action, count in sorted(action_counts.items(), key=lambda x: x[1], reverse=True):\n            st.write(f\"**{action.title()}:** {count}\")\n","size_bytes":3837},"preprocessing/advanced_signal_processing.py":{"content":"\"\"\"Advanced Signal Processing for EEG with Artifact Removal and Adaptive Filtering\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom scipy.stats import zscore\nfrom typing import Tuple, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass AdvancedSignalProcessor:\n    \"\"\"Advanced signal processing with artifact removal and adaptive filtering\"\"\"\n    \n    def __init__(self, sampling_rate: float = 256.0):\n        self.sampling_rate = sampling_rate\n    \n    def remove_artifacts_ica_simple(self, data: np.ndarray, n_components: Optional[int] = None) -> np.ndarray:\n        \"\"\"\n        Simple ICA-based artifact removal using FastICA approximation\n        \n        Args:\n            data: EEG data (channels × samples)\n            n_components: Number of ICA components (None = all channels)\n        \n        Returns:\n            Cleaned EEG data\n        \"\"\"\n        n_channels, n_samples = data.shape\n        \n        if n_components is None:\n            n_components = min(n_channels, 10)  # Limit components for efficiency\n        \n        # Center the data\n        data_centered = data - data.mean(axis=1, keepdims=True)\n        \n        # Whitening (PCA-based)\n        cov_matrix = np.cov(data_centered)\n        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n        \n        # Sort in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        \n        # Select top components\n        eigenvalues = eigenvalues[:n_components]\n        eigenvectors = eigenvectors[:, :n_components]\n        \n        # Whitening matrix\n        whitening_matrix = eigenvectors.T / np.sqrt(eigenvalues[:, np.newaxis])\n        whitened_data = whitening_matrix @ data_centered\n        \n        # Simple FastICA approximation with fixed iterations\n        W = np.random.randn(n_components, n_components)\n        W = W / np.linalg.norm(W, axis=1, keepdims=True)\n        \n        for _ in range(20):  # Limited iterations\n            W_new = (whitened_data @ np.tanh(W.T @ whitened_data).T) / n_samples\n            W_new -= W_new @ W.T @ W\n            W_new = W_new / np.linalg.norm(W_new, axis=1, keepdims=True)\n            \n            if np.allclose(np.abs(W @ W_new.T), np.eye(n_components), atol=1e-3):\n                break\n            W = W_new\n        \n        # Get independent components\n        independent_components = W @ whitened_data\n        \n        # Automatic artifact detection based on kurtosis and variance\n        artifact_threshold_kurt = 5.0\n        artifact_threshold_var = 3.0\n        \n        kurt = self._kurtosis(independent_components, axis=1)\n        variance = np.var(independent_components, axis=1)\n        var_zscore = np.abs(zscore(variance))  # type: ignore\n        \n        # Mark components with high kurtosis or extreme variance as artifacts\n        artifact_mask = (np.abs(kurt) > artifact_threshold_kurt) | (var_zscore > artifact_threshold_var)\n        \n        # Zero out artifact components\n        independent_components[artifact_mask, :] = 0\n        \n        # Reconstruct cleaned data\n        dewhitening_matrix = eigenvectors @ np.diag(np.sqrt(eigenvalues))\n        cleaned_data = dewhitening_matrix @ np.linalg.pinv(W) @ independent_components\n        \n        return cleaned_data + data.mean(axis=1, keepdims=True)\n    \n    def _kurtosis(self, data: np.ndarray, axis: int = 1) -> np.ndarray:\n        \"\"\"Compute kurtosis along axis\"\"\"\n        mean = np.mean(data, axis=axis, keepdims=True)\n        std = np.std(data, axis=axis, keepdims=True)\n        normalized = (data - mean) / (std + 1e-8)\n        return np.mean(normalized ** 4, axis=axis) - 3\n    \n    def adaptive_noise_filter(self, data: np.ndarray, method: str = 'wiener') -> np.ndarray:\n        \"\"\"\n        Adaptive noise filtering\n        \n        Args:\n            data: EEG data (channels × samples)\n            method: 'wiener' or 'wavelet'\n        \n        Returns:\n            Filtered EEG data\n        \"\"\"\n        if method == 'wiener':\n            return self._wiener_filter(data)\n        elif method == 'wavelet':\n            return self._wavelet_denoising(data)\n        else:\n            return data\n    \n    def _wiener_filter(self, data: np.ndarray, noise_power: Optional[float] = None) -> np.ndarray:\n        \"\"\"Apply Wiener filter for noise reduction\"\"\"\n        n_channels, n_samples = data.shape\n        filtered_data = np.zeros_like(data)\n        \n        for ch in range(n_channels):\n            channel_data = data[ch, :]\n            \n            # Estimate noise power from high-frequency components\n            if noise_power is None:\n                # High-pass filter to estimate noise\n                nyq = self.sampling_rate / 2\n                high_cutoff = 40.0\n                b, a = signal.butter(4, high_cutoff / nyq, btype='high')\n                noise_estimate = signal.filtfilt(b, a, channel_data)\n                est_noise_power = np.var(noise_estimate)\n            else:\n                est_noise_power = noise_power\n            \n            # Signal power\n            signal_power = np.var(channel_data)\n            \n            # Wiener gain\n            gain = max(0, 1 - est_noise_power / (signal_power + 1e-8))\n            \n            # Apply adaptive filtering\n            filtered_data[ch, :] = channel_data * gain\n        \n        return filtered_data\n    \n    def _wavelet_denoising(self, data: np.ndarray) -> np.ndarray:\n        \"\"\"Simple wavelet-based denoising using soft thresholding\"\"\"\n        n_channels, n_samples = data.shape\n        filtered_data = np.zeros_like(data)\n        \n        for ch in range(n_channels):\n            channel_data = data[ch, :]\n            \n            # Simple wavelet decomposition approximation using DWT\n            # Approximate with multi-resolution filtering\n            coeffs = []\n            temp_data = channel_data.copy()\n            \n            # 3-level decomposition\n            for level in range(3):\n                # Low-pass (approximation)\n                b, a = signal.butter(2, 0.5 / (2 ** level), btype='low')\n                approx = signal.filtfilt(b, a, temp_data)\n                \n                # Detail (difference)\n                detail = temp_data - approx\n                \n                # Soft thresholding\n                threshold = np.sqrt(2 * np.log(len(detail))) * np.std(detail)\n                detail_thresholded = np.sign(detail) * np.maximum(np.abs(detail) - threshold, 0)\n                \n                coeffs.append(detail_thresholded)\n                temp_data = approx\n            \n            # Reconstruct\n            reconstructed = temp_data\n            for detail in reversed(coeffs):\n                reconstructed = reconstructed + detail\n            \n            filtered_data[ch, :] = reconstructed\n        \n        return filtered_data\n    \n    def detect_bad_channels(self, data: np.ndarray, threshold: float = 3.0) -> Tuple[np.ndarray, list]:\n        \"\"\"\n        Detect bad channels based on amplitude and variance\n        \n        Args:\n            data: EEG data (channels × samples)\n            threshold: Z-score threshold for bad channel detection\n        \n        Returns:\n            Tuple of (cleaned_data, bad_channel_indices)\n        \"\"\"\n        n_channels, n_samples = data.shape\n        \n        # Compute channel statistics\n        channel_variance = np.var(data, axis=1)\n        channel_max = np.max(np.abs(data), axis=1)\n        \n        # Z-score based detection\n        var_zscore = np.abs(zscore(channel_variance))  # type: ignore\n        max_zscore = np.abs(zscore(channel_max))  # type: ignore\n        \n        # Bad channels: extreme variance or amplitude\n        bad_channels = np.where((var_zscore > threshold) | (max_zscore > threshold))[0]\n        \n        # Interpolate bad channels (average of neighbors)\n        cleaned_data = data.copy()\n        for bad_ch in bad_channels:\n            if bad_ch > 0 and bad_ch < n_channels - 1:\n                cleaned_data[bad_ch, :] = (data[bad_ch - 1, :] + data[bad_ch + 1, :]) / 2\n            elif bad_ch == 0 and n_channels > 1:\n                cleaned_data[bad_ch, :] = data[bad_ch + 1, :]\n            elif bad_ch == n_channels - 1 and n_channels > 1:\n                cleaned_data[bad_ch, :] = data[bad_ch - 1, :]\n        \n        return cleaned_data, bad_channels.tolist()\n    \n    def apply_advanced_preprocessing(self, data: np.ndarray, \n                                     remove_artifacts: bool = True,\n                                     adaptive_filter: bool = True,\n                                     detect_bad: bool = True) -> Tuple[np.ndarray, dict]:\n        \"\"\"\n        Apply full advanced preprocessing pipeline\n        \n        Args:\n            data: EEG data (channels × samples)\n            remove_artifacts: Apply ICA-based artifact removal\n            adaptive_filter: Apply adaptive noise filtering\n            detect_bad: Detect and interpolate bad channels\n        \n        Returns:\n            Tuple of (processed_data, processing_info)\n        \"\"\"\n        processing_info = {\n            'artifact_removal': remove_artifacts,\n            'adaptive_filtering': adaptive_filter,\n            'bad_channel_detection': detect_bad,\n            'bad_channels': []\n        }\n        \n        processed_data = data.copy()\n        \n        # Step 1: Bad channel detection\n        if detect_bad:\n            processed_data, bad_channels = self.detect_bad_channels(processed_data)\n            processing_info['bad_channels'] = bad_channels\n        \n        # Step 2: Artifact removal\n        if remove_artifacts:\n            processed_data = self.remove_artifacts_ica_simple(processed_data)\n        \n        # Step 3: Adaptive noise filtering\n        if adaptive_filter:\n            processed_data = self.adaptive_noise_filter(processed_data, method='wiener')\n        \n        return processed_data, processing_info\n","size_bytes":9943},"preprocessing/channel_selector.py":{"content":"import numpy as np\nfrom typing import List, Tuple\nfrom sklearn.feature_selection import mutual_info_classif\nfrom scipy.stats import pearsonr\n\nclass ChannelSelector:\n    \"\"\"Select optimal 20 channels from 64-channel EEG data\"\"\"\n    \n    def __init__(self, target_channels: int = 20):\n        self.target_channels = target_channels\n        \n        # Standard 10-20 system priority channels for BCI\n        self.priority_channels = [\n            'Fz', 'Cz', 'Pz', 'C3', 'C4',  # Motor cortex\n            'F3', 'F4', 'P3', 'P4',  # Frontal and parietal\n            'O1', 'O2',  # Visual cortex\n            'T7', 'T8',  # Temporal\n            'Fp1', 'Fp2',  # Frontal pole\n            'FC1', 'FC2', 'CP1', 'CP2',  # Central\n            'PO7', 'PO8'  # Parieto-occipital\n        ]\n    \n    def select_channels_by_names(self, channel_names: List[str]) -> Tuple[List[int], List[str]]:\n        \"\"\"Select channels based on standard 10-20 system names\"\"\"\n        selected_indices = []\n        selected_names = []\n        \n        # First, try to match priority channels\n        for priority in self.priority_channels:\n            for i, name in enumerate(channel_names):\n                if priority.lower() in name.lower() and i not in selected_indices:\n                    selected_indices.append(i)\n                    selected_names.append(name)\n                    break\n        \n        # If we don't have enough channels, add more based on position\n        if len(selected_indices) < self.target_channels:\n            for i, name in enumerate(channel_names):\n                if i not in selected_indices:\n                    selected_indices.append(i)\n                    selected_names.append(name)\n                    if len(selected_indices) >= self.target_channels:\n                        break\n        \n        # Take only the target number\n        selected_indices = selected_indices[:self.target_channels]\n        selected_names = selected_names[:self.target_channels]\n        \n        return selected_indices, selected_names\n    \n    def select_channels_by_variance(self, data: np.ndarray) -> List[int]:\n        \"\"\"Select channels with highest variance\"\"\"\n        variances = np.var(data, axis=1)\n        selected_indices = np.argsort(variances)[-self.target_channels:]\n        return sorted(selected_indices.tolist())\n    \n    def select_channels_by_mutual_info(self, data: np.ndarray, \n                                      labels: np.ndarray = None) -> List[int]:\n        \"\"\"Select channels based on mutual information with labels\"\"\"\n        \n        if labels is None:\n            # Use variance-based selection if no labels\n            return self.select_channels_by_variance(data)\n        \n        # Compute mutual information for each channel\n        mi_scores = []\n        for i in range(data.shape[0]):\n            # Use mean of each channel as feature\n            channel_feature = np.mean(data[i].reshape(-1, 1), axis=1)\n            mi = mutual_info_classif(channel_feature.reshape(-1, 1), labels)\n            mi_scores.append(mi[0])\n        \n        mi_scores = np.array(mi_scores)\n        selected_indices = np.argsort(mi_scores)[-self.target_channels:]\n        return sorted(selected_indices.tolist())\n    \n    def select_channels_by_correlation(self, data: np.ndarray) -> List[int]:\n        \"\"\"Select channels with low inter-channel correlation\"\"\"\n        n_channels = data.shape[0]\n        \n        # Compute correlation matrix\n        corr_matrix = np.zeros((n_channels, n_channels))\n        for i in range(n_channels):\n            for j in range(i, n_channels):\n                if i == j:\n                    corr_matrix[i, j] = 1.0\n                else:\n                    corr, _ = pearsonr(data[i], data[j])\n                    corr_matrix[i, j] = abs(corr)\n                    corr_matrix[j, i] = abs(corr)\n        \n        # Select channels with lowest average correlation\n        avg_corr = np.mean(corr_matrix, axis=1)\n        selected_indices = np.argsort(avg_corr)[:self.target_channels]\n        return sorted(selected_indices.tolist())\n    \n    def select_optimal_channels(self, data: np.ndarray, \n                               channel_names: List[str],\n                               method: str = 'names') -> Tuple[np.ndarray, List[int], List[str]]:\n        \"\"\"\n        Select optimal channels using specified method\n        \n        Args:\n            data: EEG data (channels x samples)\n            channel_names: List of channel names\n            method: 'names', 'variance', 'correlation'\n        \n        Returns:\n            selected_data, selected_indices, selected_names\n        \"\"\"\n        \n        if method == 'names':\n            selected_indices, selected_names = self.select_channels_by_names(channel_names)\n        elif method == 'variance':\n            selected_indices = self.select_channels_by_variance(data)\n            selected_names = [channel_names[i] for i in selected_indices]\n        elif method == 'correlation':\n            selected_indices = self.select_channels_by_correlation(data)\n            selected_names = [channel_names[i] for i in selected_indices]\n        else:\n            # Default to names\n            selected_indices, selected_names = self.select_channels_by_names(channel_names)\n        \n        selected_data = data[selected_indices, :]\n        \n        return selected_data, selected_indices, selected_names\n","size_bytes":5390},"preprocessing/eeg_processor.py":{"content":"import numpy as np\nimport mne\nfrom scipy import signal\nfrom typing import Tuple, List\nimport pyedflib\n\nclass EEGProcessor:\n    \"\"\"Process EEG data from EDF files\"\"\"\n    \n    def __init__(self):\n        self.sampling_rate = 256  # Default sampling rate\n        self.channels_to_select = 20\n    \n    def read_edf_file(self, file_path: str) -> Tuple[np.ndarray, List[str], float]:\n        \"\"\"Read EDF file and extract data\"\"\"\n        try:\n            # Read using pyedflib\n            edf_file = pyedflib.EdfReader(file_path)\n            n_channels = edf_file.signals_in_file\n            signal_labels = edf_file.getSignalLabels()\n            \n            # Get sampling frequency\n            self.sampling_rate = edf_file.getSampleFrequency(0)\n            \n            # Read all signals\n            signals = []\n            for i in range(n_channels):\n                signals.append(edf_file.readSignal(i))\n            \n            edf_file.close()\n            \n            # Convert to numpy array\n            data = np.array(signals)\n            \n            return data, signal_labels, self.sampling_rate\n            \n        except Exception as e:\n            raise Exception(f\"Error reading EDF file: {str(e)}\")\n    \n    def preprocess_signals(self, data: np.ndarray) -> np.ndarray:\n        \"\"\"Preprocess EEG signals\"\"\"\n        \n        # 1. Bandpass filter (0.5-50 Hz)\n        filtered_data = self._bandpass_filter(data, 0.5, 50.0, self.sampling_rate)\n        \n        # 2. Notch filter (50 Hz for power line noise)\n        notched_data = self._notch_filter(filtered_data, 50.0, self.sampling_rate)\n        \n        # 3. Normalize\n        normalized_data = self._normalize(notched_data)\n        \n        return normalized_data\n    \n    def _bandpass_filter(self, data: np.ndarray, lowcut: float, \n                        highcut: float, fs: float, order: int = 4) -> np.ndarray:\n        \"\"\"Apply bandpass filter\"\"\"\n        nyq = 0.5 * fs\n        low = lowcut / nyq\n        high = highcut / nyq\n        b, a = signal.butter(order, [low, high], btype='band')\n        \n        filtered = np.zeros_like(data)\n        for i in range(data.shape[0]):\n            filtered[i] = signal.filtfilt(b, a, data[i])\n        \n        return filtered\n    \n    def _notch_filter(self, data: np.ndarray, freq: float, \n                     fs: float, quality: float = 30.0) -> np.ndarray:\n        \"\"\"Apply notch filter\"\"\"\n        b, a = signal.iirnotch(freq, quality, fs)\n        \n        filtered = np.zeros_like(data)\n        for i in range(data.shape[0]):\n            filtered[i] = signal.filtfilt(b, a, data[i])\n        \n        return filtered\n    \n    def _normalize(self, data: np.ndarray) -> np.ndarray:\n        \"\"\"Normalize signals using z-score\"\"\"\n        normalized = np.zeros_like(data)\n        for i in range(data.shape[0]):\n            mean = np.mean(data[i])\n            std = np.std(data[i])\n            if std > 0:\n                normalized[i] = (data[i] - mean) / std\n            else:\n                normalized[i] = data[i] - mean\n        \n        return normalized\n    \n    def extract_epochs(self, data: np.ndarray, epoch_length: float = 2.0) -> np.ndarray:\n        \"\"\"Extract epochs from continuous data\"\"\"\n        samples_per_epoch = int(epoch_length * self.sampling_rate)\n        n_channels, n_samples = data.shape\n        n_epochs = n_samples // samples_per_epoch\n        \n        epochs = []\n        for i in range(n_epochs):\n            start = i * samples_per_epoch\n            end = start + samples_per_epoch\n            epoch = data[:, start:end]\n            epochs.append(epoch)\n        \n        return np.array(epochs)\n    \n    def downsample(self, data: np.ndarray, target_rate: int = 128) -> np.ndarray:\n        \"\"\"Downsample signals to target rate\"\"\"\n        if target_rate >= self.sampling_rate:\n            return data\n        \n        downsample_factor = int(self.sampling_rate / target_rate)\n        downsampled = signal.decimate(data, downsample_factor, axis=1)\n        self.sampling_rate = target_rate\n        \n        return downsampled\n","size_bytes":4066},"processing/batch_processor.py":{"content":"\"\"\"Batch Processing for Multiple EEG Files\"\"\"\nimport concurrent.futures\nimport threading\nimport time\nfrom typing import List, Dict, Tuple, Optional\nimport numpy as np\nfrom pathlib import Path\n\nfrom preprocessing.eeg_processor import EEGProcessor\nfrom preprocessing.channel_selector import ChannelSelector\nfrom preprocessing.advanced_signal_processing import AdvancedSignalProcessor\nfrom models.quantum_ml import QuantumMLModels\nfrom models.classical_ml import ClassicalMLModels\nfrom analysis.brain_metrics import BrainMetricsAnalyzer\nfrom reports.pdf_generator import PDFReportGenerator\nfrom utils.helpers import Helpers\n\n# Global lock for thread-safe EDF file reading\n_edf_read_lock = threading.Lock()\n\n\nclass BatchEEGProcessor:\n    \"\"\"Batch processing for multiple EEG files with concurrent analysis\"\"\"\n    \n    def __init__(self, max_workers: int = 4):\n        self.max_workers = max_workers\n        self.eeg_processor = EEGProcessor()\n        self.channel_selector = ChannelSelector(target_channels=20)\n        \n    def process_single_file(self, file_path: str, \n                           apply_advanced_processing: bool = True,\n                           generate_pdf: bool = True) -> Dict:\n        \"\"\"\n        Process a single EEG file\n        \n        Args:\n            file_path: Path to EDF file\n            apply_advanced_processing: Apply advanced signal processing\n            generate_pdf: Generate PDF report\n        \n        Returns:\n            Dictionary with processing results\n        \"\"\"\n        try:\n            start_time = time.time()\n            file_name = Path(file_path).name\n            \n            # Step 1: Load and preprocess (thread-safe EDF reading)\n            with _edf_read_lock:\n                data, channel_names, sampling_rate = self.eeg_processor.read_edf_file(file_path)\n            preprocessed_data = self.eeg_processor.preprocess_signals(data)\n            \n            # Step 2: Channel selection\n            selected_data, selected_channels, method_used = self.channel_selector.select_optimal_channels(\n                preprocessed_data, channel_names, method='names'\n            )\n            \n            # Step 3: Advanced signal processing (optional)\n            if apply_advanced_processing:\n                adv_processor = AdvancedSignalProcessor(sampling_rate=sampling_rate)\n                selected_data, proc_info = adv_processor.apply_advanced_preprocessing(\n                    selected_data,\n                    remove_artifacts=True,\n                    adaptive_filter=True,\n                    detect_bad=True\n                )\n            else:\n                proc_info = {}\n            \n            # Step 4: Extract features\n            classical_ml = ClassicalMLModels()\n            features = classical_ml.extract_features(selected_data)\n            \n            # Step 5: Brain metrics\n            brain_analyzer = BrainMetricsAnalyzer(sampling_rate=sampling_rate)\n            metrics = brain_analyzer.compute_multi_channel_metrics(selected_data)\n            # Extract average metrics for reporting\n            metrics = metrics.get('average', {})\n            \n            # Step 6: ML predictions (using dummy labels for demo)\n            labels = Helpers.create_dummy_labels(len(features))\n            X_train, X_test, y_train, y_test = Helpers.split_data(features, labels, test_size=0.3)\n            \n            predictions = []\n            \n            # Classical models\n            svm_model, svm_acc = classical_ml.train_svm(X_train, y_train)\n            svm_pred, svm_time = classical_ml.predict_svm(svm_model, X_test)\n            predictions.append({\n                'model_name': 'SVM',\n                'model_type': 'classical',\n                'accuracy': svm_acc,\n                'processing_time': svm_time\n            })\n            \n            # Quantum model (QSVM)\n            try:\n                qml = QuantumMLModels(n_qubits=4)\n                qsvm, qsvm_acc, qsvm_metrics = qml.train_qsvm(X_train, y_train)\n                qsvm_pred, qsvm_time = qml.predict_qsvm(qsvm, X_train, X_test)\n                predictions.append({\n                    'model_name': 'QSVM',\n                    'model_type': 'quantum',\n                    'accuracy': qsvm_acc,\n                    'processing_time': qsvm_time\n                })\n            except Exception as e:\n                print(f\"QSVM failed for {file_name}: {str(e)[:50]}\")\n            \n            # Step 7: Generate PDF (optional)\n            pdf_path = None\n            if generate_pdf:\n                try:\n                    session_data = {\n                        'filename': file_name,\n                        'upload_time': time.strftime('%Y-%m-%d %H:%M:%S'),\n                        'channels_original': data.shape[0],\n                        'channels_selected': selected_data.shape[0],\n                        'processing_status': 'completed'\n                    }\n                    \n                    pdf_gen = PDFReportGenerator()\n                    Helpers.ensure_directory('reports_output/batch')\n                    pdf_path = f\"reports_output/batch/{Path(file_name).stem}_report.pdf\"\n                    pdf_gen.create_report(session_data, metrics, predictions, pdf_path)\n                except Exception as e:\n                    print(f\"PDF generation failed for {file_name}: {str(e)[:50]}\")\n            \n            processing_time = time.time() - start_time\n            \n            return {\n                'file_name': file_name,\n                'status': 'success',\n                'processing_time': processing_time,\n                'channels_original': data.shape[0],\n                'channels_selected': selected_data.shape[0],\n                'brain_metrics': metrics,\n                'predictions': predictions,\n                'advanced_processing': proc_info,\n                'pdf_path': pdf_path\n            }\n            \n        except Exception as e:\n            return {\n                'file_name': Path(file_path).name,\n                'status': 'failed',\n                'error': str(e),\n                'processing_time': 0\n            }\n    \n    def process_batch_sequential(self, file_paths: List[str], **kwargs) -> List[Dict]:\n        \"\"\"Process files sequentially\"\"\"\n        results = []\n        for file_path in file_paths:\n            result = self.process_single_file(file_path, **kwargs)\n            results.append(result)\n        return results\n    \n    def process_batch_parallel(self, file_paths: List[str], **kwargs) -> List[Dict]:\n        \"\"\"Process files in parallel using ThreadPoolExecutor\"\"\"\n        results = []\n        \n        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            # Submit all tasks\n            future_to_file = {\n                executor.submit(self.process_single_file, file_path, **kwargs): file_path \n                for file_path in file_paths\n            }\n            \n            # Collect results as they complete\n            for future in concurrent.futures.as_completed(future_to_file):\n                file_path = future_to_file[future]\n                try:\n                    result = future.result()\n                    results.append(result)\n                except Exception as e:\n                    results.append({\n                        'file_name': Path(file_path).name,\n                        'status': 'failed',\n                        'error': str(e)\n                    })\n        \n        return results\n    \n    def get_batch_summary(self, results: List[Dict]) -> Dict:\n        \"\"\"Generate summary statistics for batch processing\"\"\"\n        total_files = len(results)\n        successful = [r for r in results if r['status'] == 'success']\n        failed = [r for r in results if r['status'] == 'failed']\n        \n        total_time = sum([r.get('processing_time', 0) for r in results])\n        avg_time = total_time / total_files if total_files > 0 else 0\n        \n        # Average accuracies\n        all_accuracies = []\n        for result in successful:\n            for pred in result.get('predictions', []):\n                all_accuracies.append(pred.get('accuracy', 0))\n        \n        avg_accuracy = np.mean(all_accuracies) if all_accuracies else 0\n        \n        summary = {\n            'total_files': total_files,\n            'successful': len(successful),\n            'failed': len(failed),\n            'total_processing_time': total_time,\n            'average_processing_time': avg_time,\n            'average_accuracy': avg_accuracy,\n            'success_rate': len(successful) / total_files if total_files > 0 else 0\n        }\n        \n        return summary\n","size_bytes":8673},"reports/pdf_generator.py":{"content":"from fpdf import FPDF\nfrom datetime import datetime\nfrom typing import Dict, List\nimport numpy as np\nimport os\n\nclass PDFReportGenerator:\n    \"\"\"Generate PDF reports for BCI analysis sessions\"\"\"\n    \n    def __init__(self):\n        self.pdf = FPDF()\n        self.pdf.set_auto_page_break(auto=True, margin=15)\n    \n    def create_report(self, session_data: Dict, metrics: Dict, \n                     predictions: List[Dict], output_path: str) -> str:\n        \"\"\"Create comprehensive PDF report\"\"\"\n        \n        # Add page\n        self.pdf.add_page()\n        \n        # Title\n        self._add_title()\n        \n        # Session information\n        self._add_session_info(session_data)\n        \n        # Brain metrics\n        self._add_brain_metrics(metrics)\n        \n        # Model predictions\n        self._add_predictions(predictions)\n        \n        # Summary\n        self._add_summary(metrics, predictions)\n        \n        # Save PDF\n        self.pdf.output(output_path)\n        \n        return output_path\n    \n    def _add_title(self):\n        \"\"\"Add report title\"\"\"\n        self.pdf.set_font('Arial', 'B', 24)\n        self.pdf.cell(0, 20, 'QuantumBCI Analysis Report', 0, 1, 'C')\n        \n        self.pdf.set_font('Arial', '', 12)\n        self.pdf.cell(0, 10, f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', 0, 1, 'C')\n        self.pdf.ln(10)\n    \n    def _add_session_info(self, session_data: Dict):\n        \"\"\"Add session information\"\"\"\n        self.pdf.set_font('Arial', 'B', 16)\n        self.pdf.cell(0, 10, 'Session Information', 0, 1)\n        self.pdf.ln(5)\n        \n        self.pdf.set_font('Arial', '', 12)\n        \n        info_items = [\n            ('Filename', session_data.get('filename', 'N/A')),\n            ('Upload Time', session_data.get('upload_time', 'N/A')),\n            ('Original Channels', str(session_data.get('channels_original', 'N/A'))),\n            ('Selected Channels', str(session_data.get('channels_selected', 'N/A'))),\n            ('Processing Status', session_data.get('processing_status', 'N/A'))\n        ]\n        \n        for label, value in info_items:\n            self.pdf.cell(60, 8, f'{label}:', 0, 0)\n            self.pdf.cell(0, 8, str(value), 0, 1)\n        \n        self.pdf.ln(10)\n    \n    def _add_brain_metrics(self, metrics: Dict):\n        \"\"\"Add brain metrics section\"\"\"\n        self.pdf.set_font('Arial', 'B', 16)\n        self.pdf.cell(0, 10, 'Brain Metrics Analysis', 0, 1)\n        self.pdf.ln(5)\n        \n        # Brain state\n        self.pdf.set_font('Arial', 'B', 12)\n        self.pdf.cell(60, 8, 'Brain State:', 0, 0)\n        self.pdf.set_font('Arial', '', 12)\n        self.pdf.cell(0, 8, metrics.get('brain_state', 'Unknown'), 0, 1)\n        self.pdf.ln(5)\n        \n        # Band powers table\n        self.pdf.set_font('Arial', 'B', 14)\n        self.pdf.cell(0, 10, 'Frequency Band Powers', 0, 1)\n        \n        self.pdf.set_font('Arial', 'B', 11)\n        self.pdf.cell(60, 8, 'Band', 1, 0, 'C')\n        self.pdf.cell(60, 8, 'Absolute Power (uV^2)', 1, 0, 'C')\n        self.pdf.cell(60, 8, 'Relative Power (%)', 1, 1, 'C')\n        \n        self.pdf.set_font('Arial', '', 11)\n        \n        bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n        for band in bands:\n            self.pdf.cell(60, 8, band.capitalize(), 1, 0)\n            self.pdf.cell(60, 8, f\"{metrics.get(f'{band}_power', 0):.4f}\", 1, 0, 'C')\n            self.pdf.cell(60, 8, f\"{metrics.get(f'{band}_relative', 0):.2f}%\", 1, 1, 'C')\n        \n        self.pdf.ln(10)\n    \n    def _add_predictions(self, predictions: List[Dict]):\n        \"\"\"Add model predictions section\"\"\"\n        self.pdf.set_font('Arial', 'B', 16)\n        self.pdf.cell(0, 10, 'Model Predictions', 0, 1)\n        self.pdf.ln(5)\n        \n        # Predictions table\n        self.pdf.set_font('Arial', 'B', 11)\n        self.pdf.cell(50, 8, 'Model', 1, 0, 'C')\n        self.pdf.cell(40, 8, 'Type', 1, 0, 'C')\n        self.pdf.cell(40, 8, 'Accuracy', 1, 0, 'C')\n        self.pdf.cell(50, 8, 'Processing Time', 1, 1, 'C')\n        \n        self.pdf.set_font('Arial', '', 11)\n        \n        for pred in predictions:\n            self.pdf.cell(50, 8, pred.get('model_name', 'N/A'), 1, 0)\n            self.pdf.cell(40, 8, pred.get('model_type', 'N/A'), 1, 0, 'C')\n            \n            accuracy = pred.get('accuracy', 0)\n            self.pdf.cell(40, 8, f\"{accuracy:.2%}\" if accuracy else 'N/A', 1, 0, 'C')\n            \n            proc_time = pred.get('processing_time', 0)\n            self.pdf.cell(50, 8, f\"{proc_time:.3f}s\" if proc_time else 'N/A', 1, 1, 'C')\n        \n        self.pdf.ln(10)\n    \n    def _add_summary(self, metrics: Dict, predictions: List[Dict]):\n        \"\"\"Add summary section\"\"\"\n        self.pdf.set_font('Arial', 'B', 16)\n        self.pdf.cell(0, 10, 'Summary & Recommendations', 0, 1)\n        self.pdf.ln(5)\n        \n        self.pdf.set_font('Arial', '', 12)\n        \n        # Best performing model\n        if predictions:\n            best_model = max(predictions, key=lambda x: x.get('accuracy', 0))\n            self.pdf.multi_cell(0, 8, f\"- Best performing model: {best_model.get('model_name', 'N/A')} \"\n                                     f\"with {best_model.get('accuracy', 0):.2%} accuracy\")\n        \n        # Brain state interpretation\n        brain_state = metrics.get('brain_state', 'Unknown')\n        self.pdf.multi_cell(0, 8, f\"- Detected brain state: {brain_state}\")\n        \n        # Dominant frequency band\n        bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n        band_powers = {band: metrics.get(f'{band}_power', 0) for band in bands}\n        dominant_band = max(band_powers.items(), key=lambda x: x[1])[0]\n        self.pdf.multi_cell(0, 8, f\"- Dominant frequency band: {dominant_band.capitalize()}\")\n        \n        # Total power\n        total_power = metrics.get('total_power', 0)\n        self.pdf.multi_cell(0, 8, f\"- Total spectral power: {total_power:.4f} uV^2\")\n        \n        self.pdf.ln(5)\n        \n        # Recommendations\n        self.pdf.set_font('Arial', 'B', 14)\n        self.pdf.cell(0, 10, 'Clinical Recommendations:', 0, 1)\n        \n        self.pdf.set_font('Arial', '', 12)\n        \n        recommendations = self._generate_recommendations(metrics)\n        for rec in recommendations:\n            self.pdf.multi_cell(0, 8, f\"- {rec}\")\n        \n    def _generate_recommendations(self, metrics: Dict) -> List[str]:\n        \"\"\"Generate clinical recommendations based on metrics\"\"\"\n        recommendations = []\n        \n        # Alpha power recommendations\n        alpha_rel = metrics.get('alpha_relative', 0)\n        if alpha_rel > 40:\n            recommendations.append(\"High alpha activity detected - suggests relaxed, wakeful state\")\n        elif alpha_rel < 20:\n            recommendations.append(\"Low alpha activity - may indicate stress or active cognitive processing\")\n        \n        # Beta power recommendations\n        beta_rel = metrics.get('beta_relative', 0)\n        if beta_rel > 40:\n            recommendations.append(\"Elevated beta activity - suggests high alertness or anxiety\")\n        \n        # Theta power recommendations\n        theta_rel = metrics.get('theta_relative', 0)\n        if theta_rel > 30:\n            recommendations.append(\"Increased theta activity - may indicate drowsiness or deep meditation\")\n        \n        # General recommendation\n        recommendations.append(\"Continue monitoring for trend analysis\")\n        recommendations.append(\"Consult with neurologist for clinical interpretation\")\n        \n        return recommendations\n","size_bytes":7573},"streaming/brain_state_ml.py":{"content":"\"\"\"ML Models for Real-Time Brain State Detection\"\"\"\nimport numpy as np\nfrom typing import Dict, Tuple\nfrom scipy import signal as scipy_signal\n\nclass BrainStateDetector:\n    \"\"\"Detect cognitive load, focus, and anxiety from EEG signals\"\"\"\n    \n    def __init__(self, sampling_rate: float = 256.0):\n        self.sampling_rate = sampling_rate\n        \n        # Baseline values for calibration (updated during rest period)\n        self.baseline = {\n            'theta_beta_ratio': 1.0,\n            'engagement_index': 1.0,\n            'frontal_asymmetry': 0.0,\n            'beta_dominance': 0.5\n        }\n        self.calibrated = False\n        \n    def compute_band_powers(self, data: np.ndarray) -> Dict[str, float]:\n        \"\"\"\n        Compute relative band powers using Welch's method\n        \n        Args:\n            data: EEG data (channels × samples)\n        \n        Returns:\n            Dictionary of band powers\n        \"\"\"\n        # Average across channels\n        avg_signal = np.mean(data, axis=0)\n        \n        # Compute PSD\n        freqs, psd = scipy_signal.welch(avg_signal, fs=self.sampling_rate, \n                                        nperseg=int(self.sampling_rate)*2)\n        \n        # Define frequency bands\n        bands = {\n            'delta': (0.5, 4),\n            'theta': (4, 8),\n            'alpha': (8, 13),\n            'beta': (13, 30),\n            'gamma': (30, 50)\n        }\n        \n        band_powers = {}\n        total_power = 0\n        \n        for band_name, (low, high) in bands.items():\n            idx = np.logical_and(freqs >= low, freqs <= high)\n            power = np.trapz(psd[idx], freqs[idx])\n            band_powers[band_name] = power\n            total_power += power\n        \n        # Relative powers\n        for band_name in bands.keys():\n            band_powers[f'{band_name}_rel'] = (band_powers[band_name] / total_power) * 100\n        \n        return band_powers\n    \n    def compute_engagement_metrics(self, band_powers: Dict[str, float]) -> Dict[str, float]:\n        \"\"\"\n        Compute engagement and attention metrics\n        \n        Returns:\n            Dictionary of engagement metrics\n        \"\"\"\n        theta = band_powers.get('theta', 0.01)\n        alpha = band_powers.get('alpha', 0.01)\n        beta = band_powers.get('beta', 0.01)\n        gamma = band_powers.get('gamma', 0.01)\n        \n        # Theta/Beta ratio (lower = better focus)\n        theta_beta_ratio = theta / (beta + 1e-8)\n        \n        # Engagement index: Beta / (Alpha + Theta)\n        engagement_index = beta / (alpha + theta + 1e-8)\n        \n        # Beta dominance (higher = more alert)\n        beta_dominance = beta / (theta + alpha + beta + gamma + 1e-8)\n        \n        return {\n            'theta_beta_ratio': theta_beta_ratio,\n            'engagement_index': engagement_index,\n            'beta_dominance': beta_dominance\n        }\n    \n    def calibrate(self, rest_data: np.ndarray):\n        \"\"\"\n        Calibrate baseline from resting state data\n        \n        Args:\n            rest_data: Resting EEG data (channels × samples), ~60 seconds\n        \"\"\"\n        band_powers = self.compute_band_powers(rest_data)\n        metrics = self.compute_engagement_metrics(band_powers)\n        \n        self.baseline = metrics.copy()\n        self.calibrated = True\n    \n    def detect_cognitive_load(self, data: np.ndarray) -> Tuple[float, str]:\n        \"\"\"\n        Detect cognitive load level (0-100)\n        \n        High cognitive load indicators:\n        - Higher theta activity\n        - Increased frontal theta\n        - Higher theta/alpha ratio\n        \n        Returns:\n            Tuple of (load_score, level_description)\n        \"\"\"\n        band_powers = self.compute_band_powers(data)\n        metrics = self.compute_engagement_metrics(band_powers)\n        \n        # Higher theta/beta ratio indicates higher cognitive load\n        theta_beta = metrics['theta_beta_ratio']\n        if self.calibrated:\n            theta_beta_normalized = (theta_beta / (self.baseline['theta_beta_ratio'] + 1e-8))\n        else:\n            theta_beta_normalized = theta_beta\n        \n        # Convert to 0-100 scale with better scaling\n        load_score = min(100, max(0, (theta_beta_normalized - 0.5) * 100))\n        \n        # Classify level\n        if load_score < 30:\n            level = \"Low\"\n        elif load_score < 60:\n            level = \"Moderate\"\n        else:\n            level = \"High\"\n        \n        return load_score, level\n    \n    def detect_focus(self, data: np.ndarray) -> Tuple[float, str]:\n        \"\"\"\n        Detect focus/attention level (0-100)\n        \n        High focus indicators:\n        - Lower theta/beta ratio\n        - Higher beta activity\n        - Lower alpha (eyes open, engaged)\n        \n        Returns:\n            Tuple of (focus_score, level_description)\n        \"\"\"\n        band_powers = self.compute_band_powers(data)\n        metrics = self.compute_engagement_metrics(band_powers)\n        \n        # Higher engagement index = better focus\n        engagement = metrics['engagement_index']\n        beta_dom = metrics['beta_dominance']\n        \n        if self.calibrated:\n            engagement_normalized = engagement / (self.baseline['engagement_index'] + 1e-8)\n            beta_dom_normalized = beta_dom / (self.baseline['beta_dominance'] + 1e-8)\n        else:\n            engagement_normalized = min(2.0, engagement)\n            beta_dom_normalized = beta_dom\n        \n        # Combine engagement and beta dominance with better scaling\n        focus_score = min(100, max(0, (engagement_normalized * 30 + beta_dom_normalized * 70 - 20)))\n        \n        # Classify level\n        if focus_score < 30:\n            level = \"Low\"\n        elif focus_score < 70:\n            level = \"Moderate\"\n        else:\n            level = \"High\"\n        \n        return focus_score, level\n    \n    def detect_anxiety(self, data: np.ndarray) -> Tuple[float, str]:\n        \"\"\"\n        Detect anxiety level (0-100)\n        \n        High anxiety indicators:\n        - Higher beta activity (especially high beta 20-30 Hz)\n        - Lower alpha\n        - Higher frontal asymmetry\n        \n        Returns:\n            Tuple of (anxiety_score, level_description)\n        \"\"\"\n        band_powers = self.compute_band_powers(data)\n        \n        beta_rel = band_powers.get('beta_rel', 0)\n        alpha_rel = band_powers.get('alpha_rel', 50)\n        theta_rel = band_powers.get('theta_rel', 0)\n        \n        # High beta + low alpha + high theta = potential anxiety\n        beta_factor = min(2.0, beta_rel / 20)  # Normalize\n        alpha_factor = max(0, 1 - (alpha_rel / 40))  # Lower alpha = higher anxiety\n        theta_factor = min(1.5, theta_rel / 15)\n        \n        anxiety_score = min(100, max(0, (beta_factor * 40 + alpha_factor * 30 + theta_factor * 30 - 30)))\n        \n        # Classify level\n        if anxiety_score < 30:\n            level = \"Low\"\n        elif anxiety_score < 60:\n            level = \"Moderate\"\n        else:\n            level = \"High\"\n        \n        return anxiety_score, level\n    \n    def analyze_window(self, data: np.ndarray) -> Dict:\n        \"\"\"\n        Complete brain state analysis for a data window\n        \n        Args:\n            data: EEG data window (channels × samples)\n        \n        Returns:\n            Dictionary with all brain state metrics\n        \"\"\"\n        band_powers = self.compute_band_powers(data)\n        \n        cognitive_load, load_level = self.detect_cognitive_load(data)\n        focus, focus_level = self.detect_focus(data)\n        anxiety, anxiety_level = self.detect_anxiety(data)\n        \n        return {\n            'cognitive_load': {\n                'score': cognitive_load,\n                'level': load_level\n            },\n            'focus': {\n                'score': focus,\n                'level': focus_level\n            },\n            'anxiety': {\n                'score': anxiety,\n                'level': anxiety_level\n            },\n            'band_powers': band_powers,\n            'calibrated': self.calibrated\n        }\n","size_bytes":8079},"streaming/edf_replay.py":{"content":"\"\"\"EDF File Replay for Simulating Live Streaming\"\"\"\nimport time\nimport numpy as np\nfrom threading import Thread, Event\nfrom typing import Callable, Optional\nfrom pathlib import Path\n\nfrom preprocessing.eeg_processor import EEGProcessor\nfrom preprocessing.channel_selector import ChannelSelector\n\n\nclass EDFReplayStreamer:\n    \"\"\"Stream EDF file data to simulate live EEG acquisition\"\"\"\n    \n    def __init__(self, edf_file_path: str, target_channels: int = 20, \n                 playback_speed: float = 1.0):\n        \"\"\"\n        Initialize EDF replay streamer\n        \n        Args:\n            edf_file_path: Path to EDF file\n            target_channels: Number of channels to stream\n            playback_speed: Speed multiplier (1.0 = real-time, 2.0 = 2x speed)\n        \"\"\"\n        self.edf_file_path = edf_file_path\n        self.target_channels = target_channels\n        self.playback_speed = playback_speed\n        \n        self.processor = EEGProcessor()\n        self.selector = ChannelSelector(target_channels=target_channels)\n        \n        # Load and preprocess data\n        self.data, self.channel_names, self.sampling_rate = self.processor.read_edf_file(edf_file_path)\n        preprocessed = self.processor.preprocess_signals(self.data)\n        self.selected_data, self.selected_channels, _ = self.selector.select_optimal_channels(\n            preprocessed, self.channel_names, method='names'\n        )\n        \n        self.n_channels, self.n_samples = self.selected_data.shape\n        \n        # Streaming state\n        self.current_sample = 0\n        self.is_streaming = False\n        self.stop_event = Event()\n        self.stream_thread: Optional[Thread] = None\n        self.callback: Optional[Callable] = None\n        \n    def start_stream(self, callback: Callable[[np.ndarray, float], None], \n                    loop: bool = True):\n        \"\"\"\n        Start streaming data\n        \n        Args:\n            callback: Function to call with each sample chunk (data, timestamp)\n            loop: Loop the file when it ends\n        \"\"\"\n        if self.is_streaming:\n            return\n        \n        self.callback = callback\n        self.is_streaming = True\n        self.stop_event.clear()\n        self.current_sample = 0\n        \n        self.stream_thread = Thread(target=self._stream_loop, args=(loop,), daemon=True)\n        self.stream_thread.start()\n    \n    def _stream_loop(self, loop: bool):\n        \"\"\"Internal streaming loop\"\"\"\n        chunk_size = 1  # Stream one sample at a time for smoothness\n        sleep_time = (chunk_size / self.sampling_rate) / self.playback_speed\n        \n        while self.is_streaming and not self.stop_event.is_set():\n            # Get next chunk\n            end_sample = min(self.current_sample + chunk_size, self.n_samples)\n            chunk = self.selected_data[:, self.current_sample:end_sample]\n            \n            if chunk.shape[1] == 0:\n                if loop:\n                    # Restart from beginning\n                    self.current_sample = 0\n                    continue\n                else:\n                    # End of file\n                    self.is_streaming = False\n                    break\n            \n            # Send chunk to callback\n            timestamp = time.time()\n            if self.callback:\n                try:\n                    if chunk.shape[1] == 1:\n                        # Single sample\n                        self.callback(chunk[:, 0], timestamp)\n                    else:\n                        # Multiple samples\n                        for i in range(chunk.shape[1]):\n                            self.callback(chunk[:, i], timestamp)\n                except Exception as e:\n                    print(f\"Callback error: {e}\")\n            \n            self.current_sample = end_sample\n            \n            # Sleep to maintain real-time rate\n            time.sleep(sleep_time)\n    \n    def stop_stream(self):\n        \"\"\"Stop streaming\"\"\"\n        self.is_streaming = False\n        self.stop_event.set()\n        if self.stream_thread:\n            self.stream_thread.join(timeout=2.0)\n    \n    def get_info(self) -> dict:\n        \"\"\"Get stream information\"\"\"\n        return {\n            'file': Path(self.edf_file_path).name,\n            'n_channels': self.n_channels,\n            'sampling_rate': self.sampling_rate,\n            'total_samples': self.n_samples,\n            'duration_seconds': self.n_samples / self.sampling_rate,\n            'current_sample': self.current_sample,\n            'progress_percent': (self.current_sample / self.n_samples) * 100,\n            'is_streaming': self.is_streaming,\n            'playback_speed': self.playback_speed\n        }\n","size_bytes":4684},"streaming/inference_engine.py":{"content":"\"\"\"Real-Time Inference Engine for Brain State Analysis\"\"\"\nimport time\nimport numpy as np\nfrom threading import Thread, Lock\nfrom typing import Dict, Optional\nfrom collections import deque\n\nfrom streaming.ring_buffer import RingBuffer\nfrom streaming.brain_state_ml import BrainStateDetector\n\n\nclass InferenceEngine:\n    \"\"\"Sliding-window inference for real-time brain state analysis\"\"\"\n    \n    def __init__(self, ring_buffer: RingBuffer, \n                 window_seconds: float = 2.0,\n                 hop_seconds: float = 0.5,\n                 smoothing_alpha: float = 0.3):\n        \"\"\"\n        Initialize inference engine\n        \n        Args:\n            ring_buffer: RingBuffer instance with continuous data\n            window_seconds: Analysis window size\n            hop_seconds: Hop size between windows (overlap = window - hop)\n            smoothing_alpha: EWMA smoothing factor (0-1, lower = more smoothing)\n        \"\"\"\n        self.ring_buffer = ring_buffer\n        self.window_seconds = window_seconds\n        self.hop_seconds = hop_seconds\n        self.smoothing_alpha = smoothing_alpha\n        \n        self.detector = BrainStateDetector(sampling_rate=ring_buffer.sampling_rate)\n        \n        # Inference state\n        self.latest_results: Optional[Dict] = None\n        self.results_lock = Lock()\n        self.is_running = False\n        self.inference_thread: Optional[Thread] = None\n        \n        # Smoothed scores (EWMA)\n        self.smoothed_scores = {\n            'cognitive_load': 0.0,\n            'focus': 0.0,\n            'anxiety': 0.0\n        }\n        \n        # History for trend analysis\n        self.history = {\n            'cognitive_load': deque(maxlen=1200),  # 10 min at 2 Hz\n            'focus': deque(maxlen=1200),\n            'anxiety': deque(maxlen=1200),\n            'timestamps': deque(maxlen=1200)\n        }\n    \n    def calibrate(self):\n        \"\"\"Calibrate detector using current buffer (rest period)\"\"\"\n        data, is_full = self.ring_buffer.get_window(window_seconds=30.0)\n        if is_full:\n            self.detector.calibrate(data)\n            return True\n        return False\n    \n    def start(self):\n        \"\"\"Start inference engine\"\"\"\n        if self.is_running:\n            return\n        \n        self.is_running = True\n        self.inference_thread = Thread(target=self._inference_loop, daemon=True)\n        self.inference_thread.start()\n    \n    def stop(self):\n        \"\"\"Stop inference engine\"\"\"\n        self.is_running = False\n        if self.inference_thread:\n            self.inference_thread.join(timeout=2.0)\n    \n    def _inference_loop(self):\n        \"\"\"Main inference loop\"\"\"\n        while self.is_running:\n            try:\n                # Get data window\n                data, is_full = self.ring_buffer.get_window(self.window_seconds)\n                \n                if not is_full:\n                    # Not enough data yet\n                    time.sleep(0.1)\n                    continue\n                \n                # Run analysis\n                results = self.detector.analyze_window(data)\n                \n                # Apply EWMA smoothing\n                self.smoothed_scores['cognitive_load'] = (\n                    self.smoothing_alpha * results['cognitive_load']['score'] +\n                    (1 - self.smoothing_alpha) * self.smoothed_scores['cognitive_load']\n                )\n                self.smoothed_scores['focus'] = (\n                    self.smoothing_alpha * results['focus']['score'] +\n                    (1 - self.smoothing_alpha) * self.smoothed_scores['focus']\n                )\n                self.smoothed_scores['anxiety'] = (\n                    self.smoothing_alpha * results['anxiety']['score'] +\n                    (1 - self.smoothing_alpha) * self.smoothed_scores['anxiety']\n                )\n                \n                # Update results with smoothed scores\n                results['cognitive_load']['smoothed_score'] = self.smoothed_scores['cognitive_load']\n                results['focus']['smoothed_score'] = self.smoothed_scores['focus']\n                results['anxiety']['smoothed_score'] = self.smoothed_scores['anxiety']\n                \n                # Store in history\n                timestamp = time.time()\n                self.history['cognitive_load'].append(self.smoothed_scores['cognitive_load'])\n                self.history['focus'].append(self.smoothed_scores['focus'])\n                self.history['anxiety'].append(self.smoothed_scores['anxiety'])\n                self.history['timestamps'].append(timestamp)\n                \n                # Update latest results\n                with self.results_lock:\n                    self.latest_results = results\n                \n                # Sleep until next window\n                time.sleep(self.hop_seconds)\n                \n            except Exception as e:\n                print(f\"Inference error: {e}\")\n                time.sleep(0.5)\n    \n    def get_latest_results(self) -> Optional[Dict]:\n        \"\"\"Get latest inference results\"\"\"\n        with self.results_lock:\n            return self.latest_results\n    \n    def get_history(self, minutes: int = 10) -> Dict:\n        \"\"\"Get historical data for trend visualization\"\"\"\n        max_points = int((minutes * 60) / self.hop_seconds)\n        \n        with self.results_lock:\n            return {\n                'cognitive_load': list(self.history['cognitive_load'])[-max_points:],\n                'focus': list(self.history['focus'])[-max_points:],\n                'anxiety': list(self.history['anxiety'])[-max_points:],\n                'timestamps': list(self.history['timestamps'])[-max_points:]\n            }\n    \n    def get_stats(self) -> Dict:\n        \"\"\"Get inference engine statistics\"\"\"\n        with self.results_lock:\n            return {\n                'window_seconds': self.window_seconds,\n                'hop_seconds': self.hop_seconds,\n                'smoothing_alpha': self.smoothing_alpha,\n                'is_running': self.is_running,\n                'calibrated': self.detector.calibrated,\n                'history_length': len(self.history['cognitive_load']),\n                'latest_update': self.history['timestamps'][-1] if self.history['timestamps'] else None\n            }\n","size_bytes":6263},"streaming/ring_buffer.py":{"content":"\"\"\"Ring Buffer for Continuous EEG Data Streaming\"\"\"\nimport numpy as np\nfrom collections import deque\nfrom threading import Lock\nfrom typing import Optional, Tuple\n\nclass RingBuffer:\n    \"\"\"Thread-safe ring buffer for continuous signal data\"\"\"\n    \n    def __init__(self, n_channels: int, buffer_seconds: float, sampling_rate: float):\n        \"\"\"\n        Initialize ring buffer\n        \n        Args:\n            n_channels: Number of EEG channels\n            buffer_seconds: Buffer size in seconds (e.g., 10-30s)\n            sampling_rate: Sampling rate in Hz\n        \"\"\"\n        self.n_channels = n_channels\n        self.sampling_rate = sampling_rate\n        self.buffer_seconds = buffer_seconds\n        self.max_samples = int(buffer_seconds * sampling_rate)\n        \n        # Thread-safe deque for each channel\n        self.buffers = [deque(maxlen=self.max_samples) for _ in range(n_channels)]\n        self.lock = Lock()\n        self.total_samples_received = 0\n        \n    def append(self, sample: np.ndarray):\n        \"\"\"\n        Append a single multi-channel sample\n        \n        Args:\n            sample: 1D array of shape (n_channels,)\n        \"\"\"\n        with self.lock:\n            for ch_idx, value in enumerate(sample):\n                self.buffers[ch_idx].append(float(value))\n            self.total_samples_received += 1\n    \n    def append_chunk(self, chunk: np.ndarray):\n        \"\"\"\n        Append a chunk of samples\n        \n        Args:\n            chunk: 2D array of shape (n_channels, n_samples)\n        \"\"\"\n        with self.lock:\n            n_samples = chunk.shape[1]\n            for ch_idx in range(self.n_channels):\n                self.buffers[ch_idx].extend(chunk[ch_idx, :])\n            self.total_samples_received += n_samples\n    \n    def get_latest(self, n_samples: Optional[int] = None) -> np.ndarray:\n        \"\"\"\n        Get latest n samples (or all if n_samples is None)\n        \n        Args:\n            n_samples: Number of samples to retrieve\n        \n        Returns:\n            2D array of shape (n_channels, n_samples)\n        \"\"\"\n        with self.lock:\n            if n_samples is None:\n                n_samples = len(self.buffers[0])\n            \n            # Get last n_samples from each channel\n            data = np.zeros((self.n_channels, min(n_samples, len(self.buffers[0]))))\n            for ch_idx in range(self.n_channels):\n                buffer_list = list(self.buffers[ch_idx])\n                actual_samples = min(n_samples, len(buffer_list))\n                data[ch_idx, :actual_samples] = buffer_list[-actual_samples:]\n            \n            return data\n    \n    def get_window(self, window_seconds: float, offset_seconds: float = 0) -> Tuple[np.ndarray, bool]:\n        \"\"\"\n        Get a time window of data\n        \n        Args:\n            window_seconds: Window size in seconds\n            offset_seconds: Offset from current time (0 = most recent)\n        \n        Returns:\n            Tuple of (data array, is_full_window boolean)\n        \"\"\"\n        n_samples = int(window_seconds * self.sampling_rate)\n        offset_samples = int(offset_seconds * self.sampling_rate)\n        \n        with self.lock:\n            available_samples = len(self.buffers[0])\n            \n            if available_samples < n_samples:\n                # Not enough data yet\n                return np.zeros((self.n_channels, n_samples)), False\n            \n            # Get window\n            start_idx = max(0, available_samples - n_samples - offset_samples)\n            end_idx = available_samples - offset_samples\n            \n            data = np.zeros((self.n_channels, end_idx - start_idx))\n            for ch_idx in range(self.n_channels):\n                buffer_list = list(self.buffers[ch_idx])\n                data[ch_idx, :] = buffer_list[start_idx:end_idx]\n            \n            return data, True\n    \n    def clear(self):\n        \"\"\"Clear all buffers\"\"\"\n        with self.lock:\n            for buffer in self.buffers:\n                buffer.clear()\n            self.total_samples_received = 0\n    \n    def get_stats(self) -> dict:\n        \"\"\"Get buffer statistics\"\"\"\n        with self.lock:\n            return {\n                'n_channels': self.n_channels,\n                'buffer_seconds': self.buffer_seconds,\n                'max_samples': self.max_samples,\n                'current_samples': len(self.buffers[0]),\n                'fill_percentage': (len(self.buffers[0]) / self.max_samples) * 100,\n                'total_received': self.total_samples_received,\n                'sampling_rate': self.sampling_rate\n            }\n","size_bytes":4602},"utils/data_export.py":{"content":"\"\"\"Data Export Utilities with Role-Based Access Control\"\"\"\nimport json\nimport csv\nfrom typing import List, Dict, Optional\nfrom pathlib import Path\nimport pandas as pd\nfrom datetime import datetime\n\nclass DataExporter:\n    \"\"\"Export EEG analysis data to various formats with role-based permissions\"\"\"\n    \n    def __init__(self, user_role: str = 'researcher'):\n        self.user_role = user_role.lower()\n    \n    def check_permission(self, export_type: str) -> bool:\n        \"\"\"Check if user has permission for export type\"\"\"\n        return PermissionManager.check_access(self.user_role, export_type)\n    \n    def export_to_csv(self, data: Dict, output_path: str, export_type: str = 'metrics') -> str:\n        \"\"\"\n        Export data to CSV format\n        \n        Args:\n            data: Dictionary with data to export\n            output_path: Path for output file\n            export_type: Type of export (raw_data, processed_data, metrics, predictions, full_report)\n        \n        Returns:\n            Path to exported file\n        \"\"\"\n        if not self.check_permission(export_type):\n            raise PermissionError(f\"Role '{self.user_role}' not permitted to export '{export_type}'\")\n        \n        # Ensure output directory exists\n        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n        \n        # Convert data to DataFrame based on type\n        if export_type == 'metrics':\n            df = self._metrics_to_dataframe(data)\n        elif export_type == 'predictions':\n            df = self._predictions_to_dataframe(data)\n        elif export_type == 'processed_data':\n            df = self._processed_data_to_dataframe(data)\n        elif export_type == 'full_report':\n            df = self._full_report_to_dataframe(data)\n        else:\n            df = pd.DataFrame(data)\n        \n        # Save to CSV\n        df.to_csv(output_path, index=False)\n        \n        return output_path\n    \n    def export_to_json(self, data: Dict, output_path: str, export_type: str = 'metrics') -> str:\n        \"\"\"\n        Export data to JSON format\n        \n        Args:\n            data: Dictionary with data to export\n            output_path: Path for output file\n            export_type: Type of export\n        \n        Returns:\n            Path to exported file\n        \"\"\"\n        if not self.check_permission(export_type):\n            raise PermissionError(f\"Role '{self.user_role}' not permitted to export '{export_type}'\")\n        \n        # Ensure output directory exists\n        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n        \n        # Add metadata\n        export_data = {\n            'metadata': {\n                'export_type': export_type,\n                'export_timestamp': datetime.now().isoformat(),\n                'exported_by_role': self.user_role\n            },\n            'data': data\n        }\n        \n        # Save to JSON\n        with open(output_path, 'w') as f:\n            json.dump(export_data, f, indent=2, default=str)\n        \n        return output_path\n    \n    def _metrics_to_dataframe(self, metrics: Dict) -> pd.DataFrame:\n        \"\"\"Convert metrics dictionary to DataFrame\"\"\"\n        rows = []\n        for key, value in metrics.items():\n            if isinstance(value, (int, float)):\n                rows.append({'metric': key, 'value': value})\n        return pd.DataFrame(rows)\n    \n    def _predictions_to_dataframe(self, predictions: List[Dict]) -> pd.DataFrame:\n        \"\"\"Convert predictions list to DataFrame\"\"\"\n        return pd.DataFrame(predictions)\n    \n    def _processed_data_to_dataframe(self, data: Dict) -> pd.DataFrame:\n        \"\"\"Convert processed EEG data to DataFrame\"\"\"\n        if 'selected_data' in data:\n            # Convert numpy array to DataFrame\n            import numpy as np\n            arr = np.array(data['selected_data'])\n            if len(arr.shape) == 2:\n                df = pd.DataFrame(arr.T)  # Transpose: samples x channels\n                df.columns = [f\"Channel_{i+1}\" for i in range(arr.shape[0])]\n                return df\n        return pd.DataFrame(data)\n    \n    def _full_report_to_dataframe(self, report: Dict) -> pd.DataFrame:\n        \"\"\"Convert full report to DataFrame\"\"\"\n        rows = []\n        \n        # Session info\n        if 'session_info' in report:\n            for key, value in report['session_info'].items():\n                rows.append({'category': 'session', 'metric': key, 'value': value})\n        \n        # Metrics\n        if 'metrics' in report:\n            for key, value in report['metrics'].items():\n                if isinstance(value, (int, float, str)):\n                    rows.append({'category': 'metric', 'metric': key, 'value': value})\n        \n        # Predictions\n        if 'predictions' in report:\n            for pred in report['predictions']:\n                model_name = pred.get('model_name', 'unknown')\n                for key, value in pred.items():\n                    if key != 'model_name':\n                        rows.append({'category': 'prediction', 'metric': f\"{model_name}_{key}\", 'value': value})\n        \n        return pd.DataFrame(rows)\n    \n    def batch_export(self, data_list: List[Dict], output_dir: str, \n                    export_format: str = 'csv', export_type: str = 'metrics') -> List[str]:\n        \"\"\"\n        Export multiple datasets\n        \n        Args:\n            data_list: List of data dictionaries\n            output_dir: Output directory\n            export_format: 'csv' or 'json'\n            export_type: Type of export\n        \n        Returns:\n            List of exported file paths\n        \"\"\"\n        Path(output_dir).mkdir(parents=True, exist_ok=True)\n        \n        exported_files = []\n        for i, data in enumerate(data_list):\n            file_name = f\"export_{i+1}.{export_format}\"\n            output_path = str(Path(output_dir) / file_name)\n            \n            if export_format == 'csv':\n                path = self.export_to_csv(data, output_path, export_type)\n            elif export_format == 'json':\n                path = self.export_to_json(data, output_path, export_type)\n            else:\n                raise ValueError(f\"Unsupported format: {export_format}\")\n            \n            exported_files.append(path)\n        \n        return exported_files\n    \n    def get_export_summary(self, exported_files: List[str]) -> Dict:\n        \"\"\"Generate summary of exported files\"\"\"\n        total_size = sum([Path(f).stat().st_size for f in exported_files if Path(f).exists()])\n        \n        return {\n            'total_files': len(exported_files),\n            'total_size_bytes': total_size,\n            'total_size_mb': round(total_size / (1024 * 1024), 2),\n            'files': exported_files\n        }\n\n\nclass PermissionManager:\n    \"\"\"Manage role-based permissions for data access\"\"\"\n    \n    ROLE_HIERARCHY = {\n        'admin': 3,\n        'doctor': 2,\n        'researcher': 1\n    }\n    \n    DATA_ACCESS_LEVELS = {\n        'raw_data': 3,        # Admin only\n        'processed_data': 2,  # Doctor and above\n        'metrics': 1,         # All roles\n        'predictions': 1,     # All roles\n        'full_report': 2,     # Doctor and above\n        'user_management': 3  # Admin only\n    }\n    \n    @classmethod\n    def check_access(cls, user_role: str, data_type: str) -> bool:\n        \"\"\"Check if role has access to data type\"\"\"\n        role_level = cls.ROLE_HIERARCHY.get(user_role.lower(), 0)\n        required_level = cls.DATA_ACCESS_LEVELS.get(data_type, 99)\n        return role_level >= required_level\n    \n    @classmethod\n    def get_accessible_data_types(cls, user_role: str) -> List[str]:\n        \"\"\"Get list of data types accessible to role\"\"\"\n        role_level = cls.ROLE_HIERARCHY.get(user_role.lower(), 0)\n        accessible = []\n        \n        for data_type, required_level in cls.DATA_ACCESS_LEVELS.items():\n            if role_level >= required_level:\n                accessible.append(data_type)\n        \n        return accessible\n","size_bytes":7987},"utils/helpers.py":{"content":"import numpy as np\nfrom typing import Tuple, List\nimport os\nfrom datetime import datetime\n\nclass Helpers:\n    \"\"\"Utility helper functions\"\"\"\n    \n    @staticmethod\n    def create_dummy_labels(n_samples: int) -> np.ndarray:\n        \"\"\"Create dummy binary labels for classification\"\"\"\n        # Create balanced labels\n        labels = np.zeros(n_samples, dtype=int)\n        labels[n_samples//2:] = 1\n        return labels\n    \n    @staticmethod\n    def split_data(data: np.ndarray, labels: np.ndarray, \n                   test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Split data into training and testing sets\"\"\"\n        n_samples = len(data)\n        n_test = int(n_samples * test_size)\n        \n        # Random shuffle\n        indices = np.random.permutation(n_samples)\n        \n        test_indices = indices[:n_test]\n        train_indices = indices[n_test:]\n        \n        X_train = data[train_indices]\n        X_test = data[test_indices]\n        y_train = labels[train_indices]\n        y_test = labels[test_indices]\n        \n        return X_train, X_test, y_train, y_test\n    \n    @staticmethod\n    def ensure_directory(path: str):\n        \"\"\"Ensure directory exists\"\"\"\n        if not os.path.exists(path):\n            os.makedirs(path)\n    \n    @staticmethod\n    def format_timestamp(timestamp: str | None = None) -> str:\n        \"\"\"Format timestamp for display\"\"\"\n        if timestamp is None:\n            return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        \n        try:\n            dt = datetime.fromisoformat(timestamp)\n            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n        except:\n            return timestamp\n    \n    @staticmethod\n    def format_duration(seconds: float) -> str:\n        \"\"\"Format duration in seconds to readable string\"\"\"\n        if seconds < 1:\n            return f\"{seconds*1000:.0f}ms\"\n        elif seconds < 60:\n            return f\"{seconds:.2f}s\"\n        else:\n            minutes = int(seconds // 60)\n            secs = seconds % 60\n            return f\"{minutes}m {secs:.0f}s\"\n","size_bytes":2077},"utils/security.py":{"content":"import hashlib\nimport secrets\nfrom cryptography.fernet import Fernet\nimport os\nimport pickle\nimport numpy as np\n\nclass SecurityManager:\n    \"\"\"Handle data encryption and security\"\"\"\n    \n    def __init__(self):\n        # Generate or load encryption key\n        self.key = self._get_or_create_key()\n        self.cipher = Fernet(self.key)\n    \n    def _get_or_create_key(self) -> bytes:\n        \"\"\"Get existing key or create new one\"\"\"\n        key_file = 'encryption.key'\n        \n        if os.path.exists(key_file):\n            with open(key_file, 'rb') as f:\n                return f.read()\n        else:\n            key = Fernet.generate_key()\n            with open(key_file, 'wb') as f:\n                f.write(key)\n            return key\n    \n    def encrypt_data(self, data: np.ndarray) -> bytes:\n        \"\"\"Encrypt numpy array data\"\"\"\n        # Serialize data\n        data_bytes = pickle.dumps(data)\n        \n        # Encrypt\n        encrypted = self.cipher.encrypt(data_bytes)\n        \n        return encrypted\n    \n    def decrypt_data(self, encrypted_data: bytes) -> np.ndarray:\n        \"\"\"Decrypt data back to numpy array\"\"\"\n        # Decrypt\n        decrypted_bytes = self.cipher.decrypt(encrypted_data)\n        \n        # Deserialize\n        data = pickle.loads(decrypted_bytes)\n        \n        return data\n    \n    def hash_data(self, data: np.ndarray) -> str:\n        \"\"\"Create hash of data for integrity verification\"\"\"\n        data_bytes = pickle.dumps(data)\n        hash_object = hashlib.sha256(data_bytes)\n        return hash_object.hexdigest()\n    \n    def verify_data_integrity(self, data: np.ndarray, expected_hash: str) -> bool:\n        \"\"\"Verify data integrity using hash\"\"\"\n        actual_hash = self.hash_data(data)\n        return actual_hash == expected_hash\n    \n    def generate_session_token(self) -> str:\n        \"\"\"Generate secure session token\"\"\"\n        return secrets.token_urlsafe(32)\n","size_bytes":1922},"visualization/signal_plots.py":{"content":"import numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom typing import List, Dict\nimport io\nimport base64\n\nclass SignalVisualizer:\n    \"\"\"Visualize EEG signals and analysis results\"\"\"\n    \n    def __init__(self):\n        plt.style.use('default')\n    \n    def plot_raw_signals(self, data: np.ndarray, channel_names: List[str], \n                        sampling_rate: float = 256, duration: float = 10) -> go.Figure:\n        \"\"\"Plot raw EEG signals using Plotly\"\"\"\n        \n        n_channels = len(channel_names)\n        samples_to_plot = int(duration * sampling_rate)\n        time = np.arange(samples_to_plot) / sampling_rate\n        \n        fig = make_subplots(\n            rows=n_channels, cols=1,\n            shared_xaxes=True,\n            vertical_spacing=0.02,\n            subplot_titles=channel_names\n        )\n        \n        for i, channel_name in enumerate(channel_names):\n            fig.add_trace(\n                go.Scatter(\n                    x=time,\n                    y=data[i, :samples_to_plot],\n                    mode='lines',\n                    name=channel_name,\n                    line=dict(width=1)\n                ),\n                row=i+1, col=1\n            )\n        \n        fig.update_layout(\n            height=200*n_channels,\n            title_text=\"20-Channel EEG Signals\",\n            showlegend=False,\n            hovermode='x unified'\n        )\n        \n        fig.update_xaxes(title_text=\"Time (s)\", row=n_channels, col=1)\n        \n        return fig\n    \n    def plot_power_spectrum(self, data: np.ndarray, sampling_rate: float = 256) -> go.Figure:\n        \"\"\"Plot power spectral density\"\"\"\n        from scipy import signal as sp_signal\n        \n        # Average across channels\n        avg_data = np.mean(data, axis=0)\n        \n        # Compute PSD\n        freqs, psd = sp_signal.welch(avg_data, fs=sampling_rate, nperseg=sampling_rate*2)\n        \n        fig = go.Figure()\n        \n        fig.add_trace(go.Scatter(\n            x=freqs,\n            y=10 * np.log10(psd),\n            mode='lines',\n            name='PSD',\n            line=dict(color='blue', width=2)\n        ))\n        \n        # Add band regions\n        bands = {\n            'Delta': (0.5, 4, 'rgba(128,0,128,0.1)'),\n            'Theta': (4, 8, 'rgba(0,0,255,0.1)'),\n            'Alpha': (8, 13, 'rgba(0,255,0,0.1)'),\n            'Beta': (13, 30, 'rgba(255,165,0,0.1)'),\n            'Gamma': (30, 50, 'rgba(255,0,0,0.1)')\n        }\n        \n        for band_name, (low, high, color) in bands.items():\n            fig.add_vrect(\n                x0=low, x1=high,\n                fillcolor=color,\n                layer=\"below\",\n                line_width=0,\n                annotation_text=band_name,\n                annotation_position=\"top left\"\n            )\n        \n        fig.update_layout(\n            title=\"Power Spectral Density\",\n            xaxis_title=\"Frequency (Hz)\",\n            yaxis_title=\"Power (dB)\",\n            height=400,\n            hovermode='x'\n        )\n        \n        return fig\n    \n    def plot_band_powers(self, metrics: Dict) -> go.Figure:\n        \"\"\"Plot frequency band powers\"\"\"\n        \n        bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n        powers = [metrics[f'{band}_power'] for band in bands]\n        \n        fig = go.Figure(data=[\n            go.Bar(\n                x=bands,\n                y=powers,\n                marker_color=['purple', 'blue', 'green', 'orange', 'red'],\n                text=[f'{p:.2f}' for p in powers],\n                textposition='auto'\n            )\n        ])\n        \n        fig.update_layout(\n            title=\"Frequency Band Powers\",\n            xaxis_title=\"Frequency Band\",\n            yaxis_title=\"Power (μV²)\",\n            height=400\n        )\n        \n        return fig\n    \n    def plot_relative_powers(self, metrics: Dict) -> go.Figure:\n        \"\"\"Plot relative band powers as pie chart\"\"\"\n        \n        bands = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n        values = [\n            metrics['delta_relative'],\n            metrics['theta_relative'],\n            metrics['alpha_relative'],\n            metrics['beta_relative'],\n            metrics['gamma_relative']\n        ]\n        \n        fig = go.Figure(data=[\n            go.Pie(\n                labels=bands,\n                values=values,\n                marker=dict(colors=['purple', 'blue', 'green', 'orange', 'red']),\n                textinfo='label+percent'\n            )\n        ])\n        \n        fig.update_layout(\n            title=\"Relative Band Power Distribution\",\n            height=400\n        )\n        \n        return fig\n    \n    def plot_model_comparison(self, predictions_dict: Dict) -> go.Figure:\n        \"\"\"Compare model accuracies\"\"\"\n        \n        models = list(predictions_dict.keys())\n        accuracies = [predictions_dict[m]['accuracy'] for m in models]\n        times = [predictions_dict[m]['processing_time'] for m in models]\n        \n        fig = make_subplots(\n            rows=1, cols=2,\n            subplot_titles=('Model Accuracy', 'Processing Time'),\n            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n        )\n        \n        fig.add_trace(\n            go.Bar(\n                x=models,\n                y=accuracies,\n                name='Accuracy',\n                marker_color='steelblue',\n                text=[f'{a:.2%}' for a in accuracies],\n                textposition='auto'\n            ),\n            row=1, col=1\n        )\n        \n        fig.add_trace(\n            go.Bar(\n                x=models,\n                y=times,\n                name='Time (s)',\n                marker_color='coral',\n                text=[f'{t:.3f}s' for t in times],\n                textposition='auto'\n            ),\n            row=1, col=2\n        )\n        \n        fig.update_layout(\n            height=400,\n            showlegend=False\n        )\n        \n        fig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\n        fig.update_yaxes(title_text=\"Time (seconds)\", row=1, col=2)\n        \n        return fig\n    \n    def create_matplotlib_figure(self, data: np.ndarray, channel_names: List[str]) -> str:\n        \"\"\"Create matplotlib figure and return as base64 string\"\"\"\n        \n        fig, axes = plt.subplots(len(channel_names), 1, figsize=(12, 2*len(channel_names)))\n        \n        if len(channel_names) == 1:\n            axes = [axes]\n        \n        for i, (ax, channel_name) in enumerate(zip(axes, channel_names)):\n            ax.plot(data[i, :1000], linewidth=0.5)\n            ax.set_ylabel(channel_name)\n            ax.set_xlim(0, 1000)\n            ax.grid(True, alpha=0.3)\n            \n            if i == len(channel_names) - 1:\n                ax.set_xlabel('Samples')\n        \n        plt.tight_layout()\n        \n        # Convert to base64\n        buffer = io.BytesIO()\n        plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')\n        buffer.seek(0)\n        image_base64 = base64.b64encode(buffer.read()).decode()\n        plt.close()\n        \n        return image_base64\n","size_bytes":7103},"pages/2_Predict_Model.py":{"content":"\"\"\"Unified Predict Model Page - Upload, Analysis, and Live Streaming\"\"\"\nimport streamlit as st\nimport sys\nfrom pathlib import Path\nimport numpy as np\nimport tempfile\nimport os\nimport plotly.graph_objects as go\nimport time\n\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom preprocessing.eeg_processor import EEGProcessor\nfrom preprocessing.channel_selector import ChannelSelector\nfrom models.quantum_ml import QuantumMLModels\nfrom analysis.brain_metrics import BrainMetricsAnalyzer\nfrom utils.security import SecurityManager\nfrom streaming.ring_buffer import RingBuffer\nfrom streaming.edf_replay import EDFReplayStreamer\nfrom streaming.inference_engine import InferenceEngine\n\n# Check authentication\nif 'authenticated' not in st.session_state or not st.session_state.authenticated:\n    st.warning(\"Please login first\")\n    st.stop()\n\nst.title(\"🔮 Predict Model - Real-Time EEG Analysis\")\nst.markdown(\"### Upload EDF → Analyze with Quantum ML → View Continuous Signal Flow\")\n\nuser = st.session_state.user\ndb_manager = st.session_state.db_manager\n\n# Initialize streaming components once\nif 'streaming_initialized' not in st.session_state:\n    st.session_state.ring_buffer = RingBuffer(n_channels=20, buffer_seconds=60.0, sampling_rate=256.0)\n    st.session_state.inference_engine = InferenceEngine(\n        st.session_state.ring_buffer,\n        window_seconds=2.0,\n        hop_seconds=0.5\n    )\n    st.session_state.streamer = None\n    st.session_state.streaming_initialized = True\n    st.session_state.is_streaming = False\n\n# Define meaningful prediction states\nPREDICTION_STATES = {\n    0: \"Relaxed State\",\n    1: \"Active/Alert State\"\n}\n\n# Create two main sections side by side\nleft_col, right_col = st.columns([1, 2])\n\n# LEFT COLUMN: Upload and Analysis Controls\nwith left_col:\n    st.markdown(\"### 📤 Upload & Process\")\n    \n    # File Upload\n    uploaded_file = st.file_uploader(\"Choose EDF file\", type=['edf'], help=\"Upload 64-channel EEG file\")\n    \n    if uploaded_file is not None and 'file_processed' not in st.session_state:\n        if st.button(\"🚀 Process & Start Streaming\", type=\"primary\", use_container_width=True):\n            # Create temp file that persists for streaming\n            tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.edf')\n            tmp_file.write(uploaded_file.getvalue())\n            tmp_file.close()\n            tmp_file_path = tmp_file.name\n            \n            try:\n                progress_bar = st.progress(0)\n                status_text = st.empty()\n                \n                status_text.text(\"⏳ Reading EEG file...\")\n                progress_bar.progress(20)\n                \n                # Initialize processors\n                eeg_processor = EEGProcessor()\n                channel_selector = ChannelSelector(target_channels=20)\n                \n                # Read and preprocess\n                data, channel_names, sampling_rate = eeg_processor.read_edf_file(tmp_file_path)\n                progress_bar.progress(30)\n                \n                status_text.text(\"⏳ Preprocessing signals...\")\n                preprocessed_data = eeg_processor.preprocess_signals(data)\n                progress_bar.progress(40)\n                \n                status_text.text(\"⏳ Selecting optimal channels...\")\n                selected_data, selected_indices, selected_names = channel_selector.select_optimal_channels(\n                    preprocessed_data, channel_names, method='names'\n                )\n                progress_bar.progress(50)\n                \n                # Compute brain metrics\n                status_text.text(\"⏳ Computing brain metrics...\")\n                brain_analyzer = BrainMetricsAnalyzer(sampling_rate)\n                \n                # Compute metrics for averaged signal\n                avg_signal = np.mean(selected_data, axis=0)\n                brain_metrics = brain_analyzer.compute_channel_metrics(avg_signal)\n                progress_bar.progress(65)\n                \n                # Run ML predictions\n                status_text.text(\"⏳ Running Quantum ML prediction...\")\n                \n                # Extract band powers\n                alpha_power = brain_metrics.get('alpha', 0)\n                beta_power = brain_metrics.get('beta', 0)\n                theta_power = brain_metrics.get('theta', 0)\n                delta_power = brain_metrics.get('delta', 0)\n                gamma_power = brain_metrics.get('gamma', 0)\n                total_power = alpha_power + beta_power + theta_power + delta_power + gamma_power\n                \n                # Prepare features for ML\n                features = np.array([\n                    alpha_power,\n                    beta_power,\n                    theta_power,\n                    delta_power,\n                    gamma_power,\n                    brain_metrics.get('alpha_relative', 0),\n                    brain_metrics.get('beta_relative', 0)\n                ]).reshape(1, -1)\n                \n                # Generate sample labels for training (in real use, you'd have labeled data)\n                X_train = np.random.randn(10, features.shape[1])\n                y_train = np.random.randint(0, 2, 10)\n                \n                # Train and predict with quantum model\n                quantum_model = QuantumMLModels()\n                qsvm_model, qsvm_accuracy, qsvm_metrics = quantum_model.train_qsvm(X_train, y_train)\n                predictions, pred_time = quantum_model.predict_qsvm(qsvm_model, X_train, features)\n                prediction = predictions[0]\n                \n                # Determine state based on brain metrics (more meaningful)\n                if beta_power > alpha_power:\n                    predicted_state = 1  # Active/Alert\n                else:\n                    predicted_state = 0  # Relaxed\n                \n                progress_bar.progress(85)\n                \n                # Create session and save\n                session_id = db_manager.create_session(\n                    user['id'],\n                    uploaded_file.name,\n                    len(channel_names),\n                    len(selected_names)\n                )\n                \n                db_manager.save_brain_metrics(\n                    session_id,\n                    alpha_power,\n                    beta_power,\n                    theta_power,\n                    delta_power,\n                    total_power,\n                    brain_metrics\n                )\n                \n                db_manager.save_prediction(\n                    session_id,\n                    'quantum',\n                    'QSVM',\n                    float(qsvm_accuracy),\n                    PREDICTION_STATES[predicted_state],\n                    pred_time\n                )\n                \n                # Store in session state\n                st.session_state['current_session_id'] = session_id\n                st.session_state['selected_data'] = selected_data\n                st.session_state['selected_names'] = selected_names\n                st.session_state['sampling_rate'] = sampling_rate\n                st.session_state['brain_metrics'] = brain_metrics\n                st.session_state['ml_prediction'] = predicted_state\n                st.session_state['ml_accuracy'] = qsvm_accuracy\n                st.session_state['temp_file_path'] = tmp_file_path\n                st.session_state['file_processed'] = True\n                \n                # Initialize streamer with the uploaded file\n                st.session_state.streamer = EDFReplayStreamer(\n                    edf_file_path=tmp_file_path,\n                    target_channels=20,\n                    playback_speed=1.0\n                )\n                \n                # Start streaming automatically\n                ring_buffer_ref = st.session_state.ring_buffer\n                def on_sample(sample, timestamp):\n                    ring_buffer_ref.append(sample)\n                \n                st.session_state.streamer.start_stream(callback=on_sample, loop=True)\n                st.session_state.inference_engine.start()\n                st.session_state.is_streaming = True\n                \n                progress_bar.progress(100)\n                status_text.text(\"\")\n                st.success(\"✅ Analysis complete! Streaming started.\")\n                db_manager.log_activity(user['id'], 'analysis', f\"Processed {uploaded_file.name}\")\n                \n                st.rerun()\n            \n            except Exception as e:\n                st.error(f\"Error: {str(e)}\")\n                db_manager.log_activity(user['id'], 'error', f\"Processing failed: {str(e)}\")\n                # Only delete file on error\n                if os.path.exists(tmp_file_path):\n                    os.remove(tmp_file_path)\n    \n    st.markdown(\"---\")\n    \n    # Analysis Results Display\n    if 'brain_metrics' in st.session_state:\n        st.markdown(\"### 📊 Analysis Results\")\n        \n        metrics = st.session_state['brain_metrics']\n        \n        st.markdown(\"**Brain Band Powers:**\")\n        st.metric(\"Alpha\", f\"{metrics.get('alpha', 0):.2f} μV²\", \n                 help=\"Relaxation and calm\")\n        st.metric(\"Beta\", f\"{metrics.get('beta', 0):.2f} μV²\", \n                 help=\"Active thinking\")\n        st.metric(\"Theta\", f\"{metrics.get('theta', 0):.2f} μV²\", \n                 help=\"Deep meditation\")\n        st.metric(\"Delta\", f\"{metrics.get('delta', 0):.2f} μV²\", \n                 help=\"Deep sleep\")\n        st.metric(\"Gamma\", f\"{metrics.get('gamma', 0):.2f} μV²\", \n                 help=\"High-level cognition\")\n        \n        st.markdown(\"---\")\n        st.markdown(\"**🤖 ML Prediction:**\")\n        pred_state = PREDICTION_STATES.get(st.session_state['ml_prediction'], \"Unknown\")\n        st.success(f\"**Predicted State:** {pred_state}\")\n        st.info(f\"**Model Accuracy:** {st.session_state['ml_accuracy']*100:.1f}%\")\n    \n    st.markdown(\"---\")\n    \n    # Stream Controls\n    st.markdown(\"### 🎮 Stream Controls\")\n    \n    col_stop, col_cal = st.columns(2)\n    \n    with col_stop:\n        if st.session_state.is_streaming:\n            if st.button(\"⏸️ Stop\", use_container_width=True, key=\"stop_btn\"):\n                if st.session_state.streamer:\n                    st.session_state.streamer.stop_stream()\n                    st.session_state.inference_engine.stop()\n                    st.session_state.is_streaming = False\n                    # Clean up temp file on stop\n                    if 'temp_file_path' in st.session_state:\n                        temp_path = st.session_state['temp_file_path']\n                        if os.path.exists(temp_path):\n                            os.remove(temp_path)\n                        del st.session_state['temp_file_path']\n                    if 'file_processed' in st.session_state:\n                        del st.session_state['file_processed']\n                    st.success(\"Stream stopped\")\n                    time.sleep(0.5)\n                    st.rerun()\n        else:\n            st.button(\"⏸️ Stop\", disabled=True, use_container_width=True)\n    \n    with col_cal:\n        if st.session_state.is_streaming:\n            if st.button(\"🎯 Calibrate\", use_container_width=True, key=\"cal_btn\"):\n                buffer_stats = st.session_state.ring_buffer.get_stats()\n                seconds_available = buffer_stats['current_samples'] / buffer_stats['sampling_rate']\n                \n                if seconds_available >= 30:\n                    success = st.session_state.inference_engine.calibrate()\n                    if success:\n                        st.success(\"✅ Calibrated!\")\n                    else:\n                        st.error(\"❌ Failed\")\n                else:\n                    st.warning(f\"⏳ Need {30-seconds_available:.1f}s more\")\n        else:\n            st.button(\"🎯 Calibrate\", disabled=True, use_container_width=True)\n    \n    # Buffer status\n    buffer_stats = st.session_state.ring_buffer.get_stats()\n    status_text = \"🟢 Streaming\" if st.session_state.is_streaming else \"🔴 Stopped\"\n    st.metric(\"Status\", status_text)\n    st.metric(\"Buffer\", f\"{buffer_stats['fill_percentage']:.1f}%\")\n    st.metric(\"Samples\", f\"{buffer_stats['total_received']:,}\")\n\n# RIGHT COLUMN: Continuous Signal Visualization\nwith right_col:\n    st.markdown(\"### 🌊 Continuous Signal Flow (20 Channels)\")\n    \n    # Create placeholders for smooth updates\n    signal_plot_placeholder = st.empty()\n    brain_states_placeholder = st.empty()\n    \n    # Get latest signal data\n    signal_data = st.session_state.ring_buffer.get_latest(n_samples=1280)  # 5 seconds\n    \n    if signal_data.shape[1] > 0:\n        # Create continuous signal plot (all 20 channels stacked)\n        fig = go.Figure()\n        \n        # Time axis\n        time_axis = np.arange(signal_data.shape[1]) / 256.0  # Convert to seconds\n        \n        # Plot each channel with offset for visibility\n        channel_names = st.session_state.get('selected_names', [f\"Ch{i+1}\" for i in range(20)])\n        \n        for i in range(min(20, signal_data.shape[0])):\n            # Offset each channel vertically\n            offset = i * 50\n            trace_data = signal_data[i, :] + offset\n            \n            fig.add_trace(go.Scatter(\n                x=time_axis,\n                y=trace_data,\n                mode='lines',\n                name=channel_names[i] if i < len(channel_names) else f\"Ch{i+1}\",\n                line=dict(color='#2196F3', width=1),  # Blue line\n                showlegend=False\n            ))\n        \n        fig.update_layout(\n            height=600,\n            xaxis_title=\"Time (seconds)\",\n            yaxis_title=\"Channels (stacked)\",\n            yaxis=dict(showticklabels=False),\n            margin=dict(l=20, r=20, t=20, b=40),\n            paper_bgcolor='rgba(0,0,0,0)',\n            plot_bgcolor='rgba(30,30,30,0.5)',\n            xaxis=dict(gridcolor='rgba(255,255,255,0.1)'),\n            hovermode='x unified'\n        )\n        \n        signal_plot_placeholder.plotly_chart(fig, use_container_width=True, key=\"signal_plot\")\n    else:\n        signal_plot_placeholder.info(\"⏳ Waiting for signal data... Upload a file and start streaming\")\n    \n    # Real-time brain states (if inference is running)\n    results = st.session_state.inference_engine.get_latest_results()\n    \n    if results:\n        with brain_states_placeholder.container():\n            st.markdown(\"---\")\n            st.markdown(\"### 🧠 Real-Time Brain States\")\n            \n            # Display gauges\n            gauge_col1, gauge_col2, gauge_col3 = st.columns(3)\n            \n            with gauge_col1:\n                cog_load = results['cognitive_load']\n                fig_gauge1 = go.Figure(go.Indicator(\n                    mode=\"gauge+number\",\n                    value=cog_load.get('smoothed_score', cog_load['score']),\n                    title={'text': \"Cognitive Load\"},\n                    gauge={\n                        'axis': {'range': [0, 100]},\n                        'bar': {'color': \"#2196F3\"},\n                        'steps': [\n                            {'range': [0, 30], 'color': \"#E8F5E9\"},\n                            {'range': [30, 70], 'color': \"#FFF9C4\"},\n                            {'range': [70, 100], 'color': \"#FFCDD2\"}\n                        ]\n                    }\n                ))\n                fig_gauge1.update_layout(height=250)\n                st.plotly_chart(fig_gauge1, use_container_width=True, key=\"gauge1\")\n            \n            with gauge_col2:\n                focus = results['focus']\n                fig_gauge2 = go.Figure(go.Indicator(\n                    mode=\"gauge+number\",\n                    value=focus.get('smoothed_score', focus['score']),\n                    title={'text': \"Focus\"},\n                    gauge={\n                        'axis': {'range': [0, 100]},\n                        'bar': {'color': \"#4CAF50\"},\n                        'steps': [\n                            {'range': [0, 30], 'color': \"#FFCDD2\"},\n                            {'range': [30, 70], 'color': \"#FFF9C4\"},\n                            {'range': [70, 100], 'color': \"#E8F5E9\"}\n                        ]\n                    }\n                ))\n                fig_gauge2.update_layout(height=250)\n                st.plotly_chart(fig_gauge2, use_container_width=True, key=\"gauge2\")\n            \n            with gauge_col3:\n                anxiety = results['anxiety']\n                fig_gauge3 = go.Figure(go.Indicator(\n                    mode=\"gauge+number\",\n                    value=anxiety.get('smoothed_score', anxiety['score']),\n                    title={'text': \"Anxiety\"},\n                    gauge={\n                        'axis': {'range': [0, 100]},\n                        'bar': {'color': \"#FF9800\"},\n                        'steps': [\n                            {'range': [0, 30], 'color': \"#E8F5E9\"},\n                            {'range': [30, 60], 'color': \"#FFF9C4\"},\n                            {'range': [60, 100], 'color': \"#FFCDD2\"}\n                        ]\n                    }\n                ))\n                fig_gauge3.update_layout(height=250)\n                st.plotly_chart(fig_gauge3, use_container_width=True, key=\"gauge3\")\n\n# Auto-refresh only when streaming (with slower rate to avoid glitches)\nif st.session_state.is_streaming:\n    time.sleep(1)  # 1 second refresh rate for smoother experience\n    st.rerun()\n","size_bytes":17492}},"version":1}